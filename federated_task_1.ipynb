{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8BKyHkMxKHfV"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from tensorflow import keras\n",
        "import tensorflow_federated as tff\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense\n",
        "from keras.initializers import GlorotUniform\n",
        "from keras.initializers import HeUniform\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "TEST_SIZE = 0.2\n",
        "NUM_CLIENTS = 10\n",
        "ACTIVE_CLIENTS = 10\n",
        "BATCH_SIZE = 512\n",
        "DROPOUT = 0.1\n",
        "EPOCHS = 20\n",
        "PREFETCH_BUFFER = 10\n",
        "NUM_ROUNDS = 5\n",
        "AGG_ALGO = \"weighted prox\"\n",
        "UNBALANCED = False\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NayDhCX6SjwE"
      },
      "outputs": [],
      "source": [
        "# Import del dataset e divisione in train e test\n",
        "train_df = pd.read_csv('datasets/train_titanic.csv')\n",
        "test_df = pd.read_csv('datasets/test_titanic.csv')\n",
        "\n",
        "test_x = test_df.drop(columns=['Transported'])\n",
        "test_y = test_df['Transported']\n",
        "\n",
        "# Funzione per il preprocessing dei dati del singolo client che divide il dataset in batch\n",
        "def preprocess(dataset):\n",
        "  return dataset.repeat(EPOCHS).batch(BATCH_SIZE).prefetch(PREFETCH_BUFFER)\n",
        "\n",
        "def client_distribution(dataset, part, num_clients):\n",
        "    positive = []\n",
        "    negative = []\n",
        "\n",
        "    dataset_0 = dataset[dataset['Transported'] == 0]\n",
        "    dataset_1 = dataset[dataset['Transported'] == 1]\n",
        "    print(len(dataset_0), len(dataset_1))\n",
        "\n",
        "    while len(positive) < len(dataset_1) and len(negative) < len(dataset_0):\n",
        "        for c in range(round(num_clients/2)):\n",
        "            positive.extend([c]*part)\n",
        "            negative.extend([c]*(4-part))\n",
        "        for c in range(round(num_clients/2), num_clients):\n",
        "            positive.extend([c]*(4-part))\n",
        "            negative.extend([c]*part)\n",
        "    print(len(negative), len(positive))\n",
        "\n",
        "    if len(dataset_1) < len(positive):\n",
        "        positive = positive[:len(dataset_1)]\n",
        "    else:\n",
        "        dataset_1 = dataset_1.iloc[:len(positive),:]\n",
        "    \n",
        "    if len(dataset_0) < len(negative):\n",
        "        negative = negative[:len(dataset_0)]\n",
        "    else:\n",
        "        dataset_0 = dataset_0.iloc[:len(negative),:]\n",
        "\n",
        "    dataset_1['client_num'] = positive\n",
        "    dataset_0['client_num'] = negative\n",
        "    ret = pd.concat([dataset_1, dataset_0])\n",
        "    print(ret.shape)\n",
        "\n",
        "    return ret\n",
        "\n",
        "# Funzione per aggiungere una colonna client_num al dataset in modo tale che ogni client abbia una percentuale di \n",
        "# righe del dataset diversa\n",
        "def client_unbalanced(dataset, num_clients):\n",
        "    client_num = []\n",
        "    prob = np.random.pareto(1, num_clients)\n",
        "    prob /= np.sum(prob)\n",
        "    print(prob)\n",
        "    for i in range(len(dataset)):\n",
        "        client_num.append(np.random.choice(num_clients, p=prob))\n",
        "    print(len(client_num))\n",
        "    print([client_num.count(x) for x in range(num_clients)])\n",
        "    dataset['client_num'] = client_num\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# Funzione per la creazione di un dataset ClientData a partire dal dataset di training a cui viene\n",
        "# aggiunta una colonna client_nums che assegna ad ogni riga un client randomico\n",
        "def create_clients(dataset, perc, num_clients=NUM_CLIENTS):\n",
        "    if UNBALANCED: \n",
        "        dataset = client_unbalanced(dataset, num_clients)\n",
        "    else:\n",
        "        dataset = client_distribution(dataset, perc, num_clients)\n",
        "\n",
        "    # Viene convertito il dataset in dizionari, uno per ogni client, con label e pixel associati\n",
        "    client_train_dataset = collections.OrderedDict()\n",
        "    grouped_dataset = dataset.groupby('client_num')\n",
        "    for key, item in grouped_dataset:\n",
        "        current_client = grouped_dataset.get_group(key)\n",
        "        data = collections.OrderedDict((('y',current_client.iloc[:,-2]), ('x', current_client.iloc[:,:-2])))\n",
        "        client_train_dataset[key] = data\n",
        "\n",
        "    # I dizionari vengono convertiti in ClientDataset\n",
        "    def serializable_dataset_fn(client_id):\n",
        "        client_data = client_train_dataset[client_id]\n",
        "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
        "\n",
        "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
        "        client_ids=list(client_train_dataset.keys()),\n",
        "        serializable_dataset_fn=serializable_dataset_fn\n",
        "    )\n",
        "\n",
        "    return tff_train_data\n",
        "\n",
        "# Creazione della lista contenente i client con i relativi dataset\n",
        "elem_spec = {}\n",
        "def init(dataset, perc, active_clients=ACTIVE_CLIENTS): \n",
        "    client_data_df = create_clients(dataset, perc)\n",
        "    client_ids = sorted(client_data_df.client_ids)[:active_clients]\n",
        "    return [preprocess(client_data_df.create_tf_dataset_for_client(x)) for x in client_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LYCsJGJFWbqt"
      },
      "outputs": [],
      "source": [
        "def create_keras_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(test_x.shape[-1], kernel_initializer = HeUniform(42), activation = 'relu', input_dim = test_x.shape[-1]))\n",
        "  model.add(Dropout(DROPOUT))\n",
        "  model.add(Dense(1024, kernel_initializer = HeUniform(42), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
        "  model.add(Dropout(DROPOUT))\n",
        "  model.add(Dense(256, kernel_initializer = HeUniform(42), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
        "  model.add(Dropout(DROPOUT))\n",
        "  model.add(Dense(128, kernel_initializer = HeUniform(42), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
        "  model.add(Dropout(DROPOUT))\n",
        "  model.add(Dense(1, kernel_initializer = GlorotUniform(42), activation = 'sigmoid'))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q3ynrxd53HzY"
      },
      "outputs": [],
      "source": [
        "def model_fn():\n",
        "  keras_model = create_keras_model()\n",
        "  return tff.learning.models.from_keras_model(\n",
        "      keras_model,\n",
        "      input_spec=elem_spec,\n",
        "      loss=tf.keras.losses.BinaryFocalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sk6mjOfycX5N"
      },
      "outputs": [],
      "source": [
        "def aggregator(algo):\n",
        "    if algo == 'weighted avg':\n",
        "        training_process = tff.learning.algorithms.build_weighted_fed_avg(model_fn, \n",
        "                                                                          client_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001),\n",
        "                                                                          server_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001))\n",
        "\n",
        "    if algo == 'unweighted avg':\n",
        "        training_process = tff.learning.algorithms.build_unweighted_fed_avg(model_fn, \n",
        "                                                                            client_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001),\n",
        "                                                                            server_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001))\n",
        "\n",
        "    if algo == 'weighted prox':\n",
        "        training_process = tff.learning.algorithms.build_weighted_fed_prox(model_fn, \n",
        "                                                                           proximal_strength=20.0, \n",
        "                                                                           client_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001),\n",
        "                                                                           server_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001))\n",
        "    if algo == 'unweighted prox':\n",
        "        training_process = tff.learning.algorithms.build_weighted_fed_prox(model_fn, \n",
        "                                                                           proximal_strength=20.0,\n",
        "                                                                           client_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001),\n",
        "                                                                           server_optimizer_fn=tff.learning.optimizers.build_adam(learning_rate=0.0001))\n",
        "    return training_process\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrJkQuCRJP9C"
      },
      "outputs": [],
      "source": [
        "federated_train_data = init(train_df, 2)\n",
        "\n",
        "print(federated_train_data)\n",
        "elem_spec = federated_train_data[0].element_spec\n",
        "training_process = aggregator(AGG_ALGO)\n",
        "\n",
        "for round_num in range(NUM_ROUNDS):\n",
        "  train_state = training_process.initialize()\n",
        "  result = training_process.next(train_state, federated_train_data)\n",
        "  train_state = result.state\n",
        "  train_metrics = result.metrics\n",
        "  print('round {:2d}, metrics={}'.format(round_num, train_metrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Numero di clients: '+str(len(federated_train_data)))\n",
        "total = 0\n",
        "for x in range(len(federated_train_data)):\n",
        "    num_elem = 0\n",
        "    for i in federated_train_data[x]:\n",
        "        num = len(list(i['x']))\n",
        "        num_elem += num\n",
        "        total += num\n",
        "    print('Numero di batch per client {}: {}\\nNumero elementi per client: {}'.format(x, str(len(federated_train_data[x])), str(num_elem)))\n",
        "print('TOT TRAIN CD: {} \\nTOT TRAIN DF: {}'.format(total, train_df.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def keras_evaluate(state, training_process):\n",
        "  keras_model = create_keras_model()\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.BinaryFocalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "  model_weights = training_process.get_model_weights(state)\n",
        "  model_weights.assign_weights_to(keras_model)\n",
        "  loss, accuracy, precision, recall = keras_model.evaluate(x=test_x, y=test_y)\n",
        "  print('\\tEval: loss={l:.3f}, accuracy={a:.3f}'.format(l=loss, a=accuracy))\n",
        "  return loss, accuracy, precision, recall "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keras_evaluate(train_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esperimenti\n",
        "==============\n",
        "\n",
        "***Algoritmo di aggregazione***\\\n",
        "Il primo set di esperimenti riguarda la strategia di aggregazione dei pesi dei client da parte dei server. Sono state valutate 4 strategie, due sulla media dei pesi (pesata e non pesata sul numero di elementi del set per client) e due con l'algoritmo di prossimità che esegue l'aggregazione dei pesi come per la media, ma con un parametro aggiuntivo che aggiunge un termine di regolarizzazione per evitare che i pesi si allontanino troppo dai pesi del server."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "federated_train_data = init(train_df, 2)\n",
        "elem_spec = federated_train_data[0].element_spec\n",
        "# Tuning del parametro di proximal strength\n",
        "def tune_proximal_strength():\n",
        "    prox_list = []\n",
        "    for i in [1.0, 10.0, 20.0, 128.0, 256.0, 512.0]:\n",
        "        training_process = aggregator('weighted prox')\n",
        "        train_state = training_process.initialize()\n",
        "        curr = []\n",
        "        for round_num in range(NUM_ROUNDS):\n",
        "            result = training_process.next(train_state, federated_train_data)\n",
        "            train_state = result.state\n",
        "            train_metrics = result.metrics\n",
        "            print('round {:2d}, metrics={}'.format(round_num, train_metrics))\n",
        "            acc_tuple = (round_num, \n",
        "                         train_metrics['client_work']['train']['binary_accuracy'], \n",
        "                         train_metrics['client_work']['train']['precision'], \n",
        "                         train_metrics['client_work']['train']['recall'])\n",
        "            curr.append(acc_tuple)\n",
        "        prox_list.append((i, curr))\n",
        "\n",
        "    return prox_list\n",
        "\n",
        "prox_list = tune_proximal_strength()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(prox_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "i = 0\n",
        "rounds = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "for algo, acc_list in prox_list:\n",
        "    rounds.append([x[0] for x in acc_list])\n",
        "    accuracies.append([x[1] for x in acc_list])\n",
        "    precisions.append([x[2] for x in acc_list])\n",
        "    recalls.append([x[3] for x in acc_list])\n",
        "    i+=1\n",
        "\n",
        "def plot_metrics(ax, rounds, metrics, labels=[1, 10, 20, 128, 256, 512]):\n",
        "    for i in range(len(metrics)):\n",
        "        ax.plot(rounds, metrics[i], label=labels[i])\n",
        "        ax.legend(loc='lower right')\n",
        "\n",
        "print(accuracies[0])\n",
        "plot_metrics(axs[0, 0], rounds[0], accuracies)\n",
        "plot_metrics(axs[0, 1], rounds[1], precisions)\n",
        "plot_metrics(axs[1, 0], rounds[2], recalls)\n",
        "\n",
        "axs[0, 0].set_title('Accuracy')\n",
        "axs[0, 1].set_title('Precision')\n",
        "axs[1, 0].set_title('Recall')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Viene creato il dataset federato assegnando ad ogni client una riga del dataset con probabilità che segue una distribuzione di pareto in modo da rendere le probabilità più sbilanciate e poter testare l'importanza o meno di considerare la media pesata. Viene fissato il numero di epoche per client per round e round totali rispettivamente a 10 e 5. Anche il numero di client è fissato a 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "federated_train_data = init(train_df, 2)\n",
        "elem_spec = federated_train_data[0].element_spec\n",
        "\n",
        "def agg_experiment():\n",
        "    prox_list = []\n",
        "    for i in ['weighted avg', 'unweighted avg', 'weighted prox', 'unweighted prox']:\n",
        "        training_process = aggregator(i)\n",
        "        train_state = training_process.initialize()\n",
        "        curr = []\n",
        "        for round_num in range(NUM_ROUNDS):\n",
        "            result = training_process.next(train_state, federated_train_data)\n",
        "            train_state = result.state\n",
        "            train_metrics = result.metrics\n",
        "            print('round {:2d}, metrics={}'.format(round_num, train_metrics))\n",
        "            acc_tuple = (round_num, \n",
        "                         train_metrics['client_work']['train']['binary_accuracy'], \n",
        "                         train_metrics['client_work']['train']['precision'], \n",
        "                         train_metrics['client_work']['train']['recall'])\n",
        "            curr.append(acc_tuple)\n",
        "        prox_list.append((i, curr))\n",
        "    return prox_list\n",
        "\n",
        "agg_algo_list = agg_experiment()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(agg_algo_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "i = 0\n",
        "rounds = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "for algo, acc_list in agg_algo_list:\n",
        "    rounds.append([x[0] for x in acc_list])\n",
        "    accuracies.append([x[1] for x in acc_list])\n",
        "    precisions.append([x[2] for x in acc_list])\n",
        "    recalls.append([x[3] for x in acc_list])\n",
        "    i+=1\n",
        "\n",
        "def plot_metrics(ax, rounds, metrics, labels=['weighted avg', 'unweighted avg', 'weighted prox', 'unweighted prox']):\n",
        "    for i in range(len(metrics)):\n",
        "        ax.plot(rounds, metrics[i], label=labels[i])\n",
        "        ax.legend(loc='lower right')\n",
        "\n",
        "print(accuracies[0])\n",
        "plot_metrics(axs[0, 0], rounds[0], accuracies)\n",
        "plot_metrics(axs[0, 1], rounds[1], precisions)\n",
        "plot_metrics(axs[1, 0], rounds[2], recalls)\n",
        "\n",
        "axs[0, 0].set_title('Accuracy')\n",
        "axs[0, 1].set_title('Precision')\n",
        "axs[1, 0].set_title('Recall')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Numero e percentuale client***\\\n",
        "Vengono fatti una serie di esperimenti al variare del numero di client, con 10, 50, 100 e 500 client, individuando con 500 il limite massimo di client supportati a livello di risorse. Per ogni blocco di client viene perso il 25% 50% 75% 100%. Viene fissato il numero di epoche per client per round e numero di round come nel caso precedente. Questa volta i client vengono presi in modo bilanciato, con circa lo stesso numero di entry ciascuno e le label divise 50% di positive e 50% negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def client_perc_experiment():\n",
        "    client_list = []\n",
        "    eval_list = []\n",
        "    for i in [10, 50, 100, 500]:\n",
        "        perc_list = []\n",
        "        for j in [0.25, 0.50, 0.75, 1]:\n",
        "            federated_train_data = init(train_df, perc = 2, active_clients=math.floor(i*j))\n",
        "            global elem_spec \n",
        "            elem_spec = federated_train_data[0].element_spec\n",
        "            training_process = aggregator('weighted avg')\n",
        "            train_state = training_process.initialize()\n",
        "  \n",
        "            curr = []\n",
        "            for round_num in range(NUM_ROUNDS):\n",
        "                result = training_process.next(train_state, federated_train_data)\n",
        "                train_state = result.state\n",
        "                train_metrics = result.metrics\n",
        "                print('round {:2d}, metrics={}'.format(round_num, train_metrics))\n",
        "                acc_tuple = (round_num, \n",
        "                             train_metrics['client_work']['train']['binary_accuracy'], \n",
        "                             train_metrics['client_work']['train']['precision'], \n",
        "                             train_metrics['client_work']['train']['recall'])\n",
        "                curr.append(acc_tuple)\n",
        "            eval = keras_evaluate(train_state, training_process)\n",
        "            eval_list.append((i, j, eval))\n",
        "            perc_list.append((j, curr))\n",
        "        client_list.append((i, perc_list))\n",
        "    return client_list, eval_list\n",
        "\n",
        "client_list, eval_list = client_perc_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_metric(data, metric_index, metric_name):\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    for i, (clients, portions_data) in enumerate(data):\n",
        "        ax = axs[i // 2, i % 2]\n",
        "        for portion, epoch_data in portions_data:\n",
        "            epochs = [e[0] for e in epoch_data]\n",
        "            metric_values = [e[metric_index] for e in epoch_data]\n",
        "            ax.plot(epochs, metric_values, label=f'{portion*100}% data')\n",
        "        \n",
        "        ax.set_title(f'{clients} Clients')\n",
        "        ax.set_xlabel('Metrics')\n",
        "        ax.set_ylabel(metric_name)\n",
        "        ax.legend()\n",
        "        ax.grid(True) \n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.show()\n",
        "\n",
        "plot_metric(client_list, 1, 'Accuracy') \n",
        "plot_metric(client_list, 2, 'Precision')  \n",
        "plot_metric(client_list, 3, 'Recall') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(eval_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Distribuzione delle label***\\\n",
        "Vengono fatti una serie di esperimenti per valutare le prestazioni al variare della percentuale che ogni client osserva delle due label. I parametri di epoche per round e numero di round vengono lasciati invariati, si scelgono 10 client che vengono presi tutti quanti. Gli esperimenti fatti prevedno che:\n",
        "* I client osservano per metà il 75% di label positive ed il 25% negative e per metà il viceversa\n",
        "* Tutti i client osservano il 50% di label positive ed il 50% negative\n",
        "* Metà dei client osservano solo esempi negativi, metà solo positivi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def client_perc_experiment():\n",
        "    eval_list = []\n",
        "    perc_list = []\n",
        "    for i in [4, 3, 2]:\n",
        "        federated_train_data = init(train_df, perc=i, active_clients=NUM_CLIENTS)\n",
        "        global elem_spec \n",
        "        elem_spec = federated_train_data[0].element_spec\n",
        "        training_process = aggregator('weighted avg')\n",
        "        train_state = training_process.initialize()\n",
        "\n",
        "        curr = []\n",
        "        for round_num in range(NUM_ROUNDS):\n",
        "            result = training_process.next(train_state, federated_train_data)\n",
        "            train_state = result.state\n",
        "            train_metrics = result.metrics\n",
        "            print('round {:2d}, metrics={}'.format(round_num, train_metrics))\n",
        "            acc_tuple = (round_num, \n",
        "                         train_metrics['client_work']['train']['binary_accuracy'], \n",
        "                         train_metrics['client_work']['train']['precision'], \n",
        "                         train_metrics['client_work']['train']['recall'])\n",
        "            curr.append(acc_tuple)\n",
        "        eval = keras_evaluate(train_state, training_process)\n",
        "        eval_list.append((i, eval))\n",
        "        perc_list.append((i, curr))\n",
        "    return perc_list, eval_list\n",
        "    \n",
        "perc_list, eval_list = client_perc_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(eval_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n",
        "i = 0\n",
        "rounds = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "for algo, acc_list in perc_list:\n",
        "    rounds.append([x[0] for x in acc_list])\n",
        "    accuracies.append([x[1] for x in acc_list])\n",
        "    precisions.append([x[2] for x in acc_list])\n",
        "    recalls.append([x[3] for x in acc_list])\n",
        "    i+=1\n",
        "\n",
        "def plot_metrics(ax, rounds, metrics, labels=['100/0', '75/25', '50/50']):\n",
        "    for i in range(len(metrics)):\n",
        "        ax.plot(rounds, metrics[i], label=labels[i])\n",
        "        ax.legend(loc='lower right')\n",
        "\n",
        "print(accuracies[0])\n",
        "plot_metrics(axs[0, 0], rounds[0], accuracies)\n",
        "plot_metrics(axs[0, 1], rounds[1], precisions)\n",
        "plot_metrics(axs[1, 0], rounds[2], recalls)\n",
        "\n",
        "axs[0, 0].set_title('Accuracy')\n",
        "axs[0, 1].set_title('Precision')\n",
        "axs[1, 0].set_title('Recall')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "federated_learning_for_image_classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
