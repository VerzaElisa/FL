{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 20:17:48.131092: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-17 20:17:48.131141: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-17 20:17:48.131190: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-17 20:17:48.146489: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "/home/ella/Documents/FL/venv-federated/lib/python3.9/site-packages/tensorflow_federated\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import HeUniform\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLIENTS = 5\n",
    "ACTIVE_CLIENTS = 5\n",
    "BATCH_SIZE = 5\n",
    "path = os.path.dirname(tff.__file__)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibili:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow sta usando la GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 20:17:51.361795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:17:51.372474: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:17:51.372669: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Lista delle GPU disponibili\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs disponibili: \", gpus)\n",
    "\n",
    "# Verifica se TensorFlow utilizza la GPU\n",
    "if gpus:\n",
    "    print(\"TensorFlow sta usando la GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow non sta usando la GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "train_df = pd.read_csv('datasets/train.csv')\n",
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "# Viene diviso il train set in train e validation set\n",
    "train_df, val_df = train_test_split(train_df, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "train_x = train_df.iloc[:,:-1]\n",
    "train_y = train_df.iloc[:,-1]\n",
    "\n",
    "val_x = val_df.iloc[:,:-1]\n",
    "val_y = val_df.iloc[:,-1]\n",
    "\n",
    "test_x = test_df.iloc[:,:-1]\n",
    "test_y = test_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare la dipendenza tra feature categoriche con il chi-square test.\n",
    "# Il test ha come ipotesi nulla che le due variabili siano indipendenti. Quindi con un p-value\n",
    "# minore di 0.05 si rigetta l'ipotesi nulla e si accetta che le due variabili sono dipendenti.\n",
    "def chi_square(f1, f2):\n",
    "    crosstab_result=pd.crosstab(index=f1,columns=f2)\n",
    "    return chi2_contingency(crosstab_result)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategia: Home_planet\n",
    "# Si nota la forte correlazione tra group ed home planet/destination e quindi per i nan si possono assegnre i valori del gruppo\n",
    "# (che saranno uguali alla moda). Restano problematici i gruppi composti da una sola persona, si introduce quindi una nuova categoria\n",
    "# di home planet e destination per persona con origine o destinazione sconosciuta.\n",
    "\n",
    "def mv_hp_d(dataset):\n",
    "    print(\"-------------------------- HomePlanet -------------------------\")\n",
    "\n",
    "    # HomePlanet\n",
    "    p = chi_square(dataset['HomePlanet'], dataset['Group'])\n",
    "    print(f\"Le feature HomePlanet e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                           else \"Le feature Destination e Group non sono correlate\")\n",
    "\n",
    "    print(f\"Numero di persone con HomePlanet nullo: {str(dataset['HomePlanet'].isna().sum())}\")\n",
    "    dataset['HomePlanet'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['HomePlanet'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['HomePlanet'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['HomePlanet'].transform(lambda x: x.fillna(\"unknown\"))\n",
    "    print(f\"Numero di persone con HomePlanet nullo: {str(dataset['HomePlanet'].isna().sum())}\")\n",
    "\n",
    "    # Destination\n",
    "    print(\"-------------------------- Destination ------------------------\")\n",
    "    p = chi_square(dataset['Destination'], dataset['Group'])\n",
    "    print(f\"Le feature Destination e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                           else \"Le feature Destination e Group non sono correlate\")\n",
    "    \n",
    "    print(f\"Numero di persone con Destination nullo: {str(dataset['Destination'].isna().sum())}\")\n",
    "    dataset['Destination'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Destination'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Destination'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['Destination'].transform(lambda x: x.fillna(\"unknown\"))\n",
    "    print(f\"Numero di persone con Destination nullo: {str(dataset['Destination'].isna().sum())}\")\n",
    "\n",
    "# Strategia: Age\n",
    "# Si distinguono 3 casi di persone con Age nullo: persone sole, persone con famiglia che non spendono e persone con famiglia che spendono.\n",
    "# Per assegnare l'età si usa la mediana del caso di appartenenza, immaginando che è meno probabile che una persona sola sia un bambino\n",
    "# e che al contrario è più probabile che una persona che non spende, ma è in un gruppo lo sia.\n",
    "def mv_age(dataset):\n",
    "    print(\"----------------------------- Age -----------------------------\")\n",
    "    solo = dataset['Solo']==1\n",
    "    family_no_spending = (dataset['Family_size']>1) & (dataset['No_spending']==1)\n",
    "    family_spending = (dataset['Family_size']>1) & (dataset['No_spending']==0)\n",
    "    \n",
    "    print(f\"Numero di persone con Age nullo: {str(dataset['Age'].isna().sum())}, di cui:\")\n",
    "    print(f\"Persone sole: {str(dataset['Age'][solo].isna().sum())}\")\n",
    "    print(f\"Persone con famiglia che non spendono: {str(dataset['Age'][family_no_spending].isna().sum())}\")   \n",
    "    print(f\"Persone con famiglia che spendono: {str(dataset['Age'][family_spending].isna().sum())}\")\n",
    "\n",
    "    dataset['Age'][solo] = dataset[solo]['Age'].transform(lambda x: x.fillna(dataset[solo]['Age'].median()))\n",
    "    dataset['Age'][family_no_spending] = dataset[family_no_spending]['Age'].transform(lambda x: x.fillna(dataset[family_no_spending]['Age'].median()))\n",
    "    dataset['Age'][family_spending] = dataset[family_spending]['Age'].transform(lambda x: x.fillna(dataset[family_spending]['Age'].median()))\n",
    "\n",
    "    print(f\"Numero di persone con Age nullo: {str(dataset['Age'].isna().sum())}\")   \n",
    "\n",
    "\n",
    "# Strategia: Surname\n",
    "# Si osserva che i gruppi sono per gran parte composti da persone con lo stesso cognome, quindi si può assegnare la moda del cognome del gruppo\n",
    "# alle persone con cognome nullo. Per i gruppi composti da una sola persona si assegna cognome 'unknown'.\n",
    "def mv_surname(dataset):\n",
    "    print(\"------------------------------ Surname ------------------------\")\n",
    "\n",
    "    p = chi_square(dataset['Surname'], dataset['Group'])\n",
    "    print(f\"Le feature Surname e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                       else \"Le feature Surname e Group non sono correlate\")\n",
    "\n",
    "    print(f\"Numero di persone con Surname nullo: {str(dataset['Surname'].isna().sum())}\")\n",
    "    dataset['Surname'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Surname'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Surname'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['Surname'].transform(lambda x: x.fillna(\"Unknown\"))\n",
    "    print(f\"Numero di persone con Surname nullo: {str(dataset['Surname'].isna().sum())}\")\n",
    "\n",
    "# Strategia: RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "# Si sostituiscono i valori nulli con la media di spesa delle altre categorie non nulle, dopo aver osservato che ogni persona ha almeno un valore\n",
    "# di spesa non nullo. Ad esempio, se una persona ha spesa nulla per RoomService e ShoppingMall, ma ha spesa per FoodCourt e Spa, si assegna la media\n",
    "# di FoodCourt e Spa per RoomService e ShoppingMall.\n",
    "def mv_exp(dataset):\n",
    "    print(\"------ RoomService, FoodCourt, ShoppingMall, Spa, VRDeck ------\")\n",
    "    print(f\"Persone con servizi nulli: {str(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].isnull().any(axis=1).sum())}\")\n",
    "    # Per ogni persona con almeno un servizio nullo, si calcola la media delle spese non nulle\n",
    "    dataset['RoomService'] = dataset['RoomService'].fillna(dataset[['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['FoodCourt'] = dataset['FoodCourt'].fillna(dataset[['RoomService', 'ShoppingMall', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['ShoppingMall'] = dataset['ShoppingMall'].fillna(dataset[['RoomService', 'FoodCourt', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['Spa'] = dataset['Spa'].fillna(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'VRDeck']].mean(axis=1))\n",
    "    dataset['VRDeck'] = dataset['VRDeck'].fillna(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa']].mean(axis=1))\n",
    "    print(f\"Persone con servizi nulli: {str(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].isnull().any(axis=1).sum())}\")\n",
    "\n",
    "# Controllare se i gruppi hanno tutti lo stesso valore di cabin_side\n",
    "def mv_cabins(dataset):\n",
    "    print(\"------------------------- Cabin_side --------------------------\")\n",
    "    p = chi_square(dataset['Cabin_side'], dataset['Group'])\n",
    "    print(f\"Le feature Cabin_side e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                          else \"Le feature Cabin_side e Group non sono correlate\")\n",
    "    print(f\"Numero di persone con Cabin_side nullo: {str(dataset['Cabin_side'].isna().sum())}\")\n",
    "    dataset['Cabin_side'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Cabin_side'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Cabin_side'][(dataset['Solo']==1)] = dataset['Cabin_side'][(dataset['Solo']==1)].fillna('unknown')\n",
    "    print(f\"Numero di persone con Cabin_side nullo: {str(dataset['Cabin_side'].isna().sum())}\")\n",
    "\n",
    "    print(\"------------------------ Cabin_number -------------------------\")\n",
    "    p = chi_square(dataset['Cabin_number'], dataset['Group'])\n",
    "    print(f\"Le feature Cabin_number e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                            else \"Le feature Cabin_number e Group non sono correlate\")\n",
    "    print(f\"Numero di persone con Cabin_number nullo: {str(dataset['Cabin_number'].isna().sum())}\")\n",
    "    dataset['Cabin_number'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Cabin_number'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Cabin_number'][(dataset['Solo']==1)] = dataset['Cabin_number'][(dataset['Solo']==1)].fillna(0)\n",
    "    print(f\"Numero di persone con Cabin_number nullo: {str(dataset['Cabin_number'].isna().sum())}\")\n",
    "    \n",
    "    print(\"------------------------- Cabin_deck --------------------------\")\n",
    "    p = chi_square(dataset['Cabin_deck'], dataset['HomePlanet'])\n",
    "    print(f\"Le feature Cabin_deck e HomePlanet sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                               else \"Le feature Cabin_deck e HomePlanet non sono correlate\")\n",
    "    print(f\"Numero di persone con Cabin_deck nullo: {str(dataset['Cabin_deck'].isna().sum())}\")\n",
    "    dataset['Cabin_deck'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('HomePlanet')['Cabin_deck'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Cabin_deck'][(dataset['Solo']==1)] = dataset['Cabin_deck'][(dataset['Solo']==1)].fillna('unknown')\n",
    "    print(f\"Numero di persone con Cabin_deck nullo: {str(dataset['Cabin_deck'].isna().sum())}\")\n",
    "\n",
    "# Strategia: VIP, CrioSleep\n",
    "# Per le feature VIP e CrioSleep si assegna il valore della moda a tutti i valori nulli.\n",
    "def mv_vip_crio(dataset):\n",
    "    print(\"----------------------------- VIP, CryoSleep ------------------\")\n",
    "    print(f\"Numero di persone con VIP nullo: {str(dataset['VIP'].isna().sum())}\")\n",
    "    dataset['VIP'] = dataset['VIP'].fillna(dataset['VIP'].mode()[0])\n",
    "    print(f\"Numero di persone con VIP nullo: {str(dataset['VIP'].isna().sum())}\")\n",
    "\n",
    "    print(f\"Numero di persone con CryoSleep nullo: {str(dataset['CryoSleep'].isna().sum())}\")\n",
    "    dataset['CryoSleep'] = dataset['CryoSleep'].fillna(dataset['CryoSleep'].mode()[0])\n",
    "    print(f\"Numero di persone con CryoSleep nullo: {str(dataset['CryoSleep'].isna().sum())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age',\n",
      "       'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
      "       'Name'],\n",
      "      dtype='object')\n",
      "------ RoomService, FoodCourt, ShoppingMall, Spa, VRDeck ------\n",
      "Persone con servizi nulli: 691\n",
      "Persone con servizi nulli: 0\n",
      "-------------------------- HomePlanet -------------------------\n",
      "Le feature HomePlanet e Group sono correlate, con p-value7.383208949075836e-101\n",
      "Numero di persone con HomePlanet nullo: 168\n",
      "Numero di persone con HomePlanet nullo: 0\n",
      "-------------------------- Destination ------------------------\n",
      "Le feature Destination e Group sono correlate, con p-value0.00016495054761429579\n",
      "Numero di persone con Destination nullo: 139\n",
      "Numero di persone con Destination nullo: 0\n",
      "------------------------------ Surname ------------------------\n",
      "Le feature Surname e Group sono correlate, con p-value0.0\n",
      "Numero di persone con Surname nullo: 159\n",
      "Numero di persone con Surname nullo: 0\n",
      "----------------------------- Age -----------------------------\n",
      "Numero di persone con Age nullo: 148, di cui:\n",
      "Persone sole: 87\n",
      "Persone con famiglia che non spendono: 40\n",
      "Persone con famiglia che spendono: 21\n",
      "Numero di persone con Age nullo: 0\n",
      "------------------------- Cabin_side --------------------------\n",
      "Le feature Cabin_side e Group sono correlate, con p-value3.8625169822992095e-51\n",
      "Numero di persone con Cabin_side nullo: 158\n",
      "Numero di persone con Cabin_side nullo: 0\n",
      "------------------------ Cabin_number -------------------------\n",
      "Le feature Cabin_number e Group sono correlate, con p-value0.0\n",
      "Numero di persone con Cabin_number nullo: 158\n",
      "Numero di persone con Cabin_number nullo: 0\n",
      "------------------------- Cabin_deck --------------------------\n",
      "Le feature Cabin_deck e HomePlanet sono correlate, con p-value0.0\n",
      "Numero di persone con Cabin_deck nullo: 158\n",
      "Numero di persone con Cabin_deck nullo: 0\n",
      "----------------------------- VIP, CryoSleep ------------------\n",
      "Numero di persone con VIP nullo: 162\n",
      "Numero di persone con VIP nullo: 0\n",
      "Numero di persone con CryoSleep nullo: 177\n",
      "Numero di persone con CryoSleep nullo: 0\n",
      "Index(['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age',\n",
      "       'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',\n",
      "       'Name'],\n",
      "      dtype='object')\n",
      "------ RoomService, FoodCourt, ShoppingMall, Spa, VRDeck ------\n",
      "Persone con servizi nulli: 217\n",
      "Persone con servizi nulli: 0\n",
      "-------------------------- HomePlanet -------------------------\n",
      "Le feature HomePlanet e Group sono correlate, con p-value0.0003119608334944179\n",
      "Numero di persone con HomePlanet nullo: 33\n",
      "Numero di persone con HomePlanet nullo: 0\n",
      "-------------------------- Destination ------------------------\n",
      "Le feature Destination e Group non sono correlate\n",
      "Numero di persone con Destination nullo: 43\n",
      "Numero di persone con Destination nullo: 0\n",
      "------------------------------ Surname ------------------------\n",
      "Le feature Surname e Group sono correlate, con p-value0.0\n",
      "Numero di persone con Surname nullo: 41\n",
      "Numero di persone con Surname nullo: 0\n",
      "----------------------------- Age -----------------------------\n",
      "Numero di persone con Age nullo: 31, di cui:\n",
      "Persone sole: 26\n",
      "Persone con famiglia che non spendono: 3\n",
      "Persone con famiglia che spendono: 2\n",
      "Numero di persone con Age nullo: 0\n",
      "------------------------- Cabin_side --------------------------\n",
      "Le feature Cabin_side e Group sono correlate, con p-value0.007907915616871108\n",
      "Numero di persone con Cabin_side nullo: 41\n",
      "Numero di persone con Cabin_side nullo: 0\n",
      "------------------------ Cabin_number -------------------------\n",
      "Le feature Cabin_number e Group sono correlate, con p-value0.0\n",
      "Numero di persone con Cabin_number nullo: 41\n",
      "Numero di persone con Cabin_number nullo: 0\n",
      "------------------------- Cabin_deck --------------------------\n",
      "Le feature Cabin_deck e HomePlanet sono correlate, con p-value0.0\n",
      "Numero di persone con Cabin_deck nullo: 41\n",
      "Numero di persone con Cabin_deck nullo: 0\n",
      "----------------------------- VIP, CryoSleep ------------------\n",
      "Numero di persone con VIP nullo: 41\n",
      "Numero di persone con VIP nullo: 0\n",
      "Numero di persone con CryoSleep nullo: 40\n",
      "Numero di persone con CryoSleep nullo: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_data(dataset):\n",
    "    print(dataset.columns)\n",
    "    # Viene aggiunta una colonna per contare il numero di persone nel gruppo di appartenenza e se la persona è da sola\n",
    "    dataset['Group'] = dataset['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "    dataset['Group_size']=dataset['Group'].map(lambda x: dataset['Group'].value_counts()[x])\n",
    "    dataset['Solo']=(dataset['Group_size']==1).astype(int)\n",
    "\n",
    "    # Viene creata una colonna per il cognome e si rimuove la colonna Name\n",
    "    dataset['Name'].fillna('Unknown Unknown', inplace=True)\n",
    "    dataset['Surname']=dataset['Name'].str.split().str[-1]\n",
    "    dataset.loc[dataset['Surname']=='Unknown','Surname']=np.nan\n",
    "    dataset.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "    # Vengono riempiti i valori nulli delle colonne RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "    mv_exp(dataset)\n",
    "    \n",
    "    # Vengono prese tutte le colonne che rappresentano le spese e si aggiunge una colonna per contare il\n",
    "    # totale speso dalla persona e una colonna booleana per indicare se la persona non ha speso nulla\n",
    "    exp_feats=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    dataset['Expenditure']=dataset[exp_feats].sum(axis=1)\n",
    "    dataset['No_spending']=(dataset['Expenditure']==0).astype(int)\n",
    "\n",
    "    # Vengono riempiti i valori nulli della colonna HomePlanet, Destination, Surmane\n",
    "    mv_hp_d(dataset)\n",
    "    mv_surname(dataset)\n",
    "\n",
    "    # Viene aggiunta una colonna per contare le persone che hanno lo stesso cognome\n",
    "    dataset['Family_size']=dataset[(dataset['Surname']!='Unknown')].groupby('Group')['Surname'].transform('count')\n",
    "    dataset.loc[dataset['Surname']=='Unknown','Family_size']=1\n",
    "    dataset.loc[dataset['Family_size']>100,'Family_size']=np.nan\n",
    "\n",
    "    # Vengono riempiti i valori nulli della colonna Age\n",
    "    mv_age(dataset)\n",
    "\n",
    "\n",
    "    # Viene aggiunta una colonna che assegna ogni passeggero al gruppo di età di appartenenza\n",
    "    dataset['Age_group']=0\n",
    "    dataset.loc[dataset['Age']<=12,'Age_group']='Age_0-12'\n",
    "    dataset.loc[(dataset['Age']>12) & (dataset['Age']<18),'Age_group']='Age_13-17'\n",
    "    dataset.loc[(dataset['Age']>=18) & (dataset['Age']<=25),'Age_group']='Age_18-25'\n",
    "    dataset.loc[(dataset['Age']>25) & (dataset['Age']<=30),'Age_group']='Age_26-30'\n",
    "    dataset.loc[(dataset['Age']>30) & (dataset['Age']<=50),'Age_group']='Age_31-50'\n",
    "    dataset.loc[dataset['Age']>50,'Age_group']='Age_51+'\n",
    "\n",
    "    # Separazione della colonna 'Cabin' nelle colonne deck, number e side\n",
    "    dataset['Cabin'].fillna('Z/9999/Z', inplace=True)\n",
    "\n",
    "    dataset['Cabin_deck'] = dataset['Cabin'].apply(lambda x: x.split('/')[0])\n",
    "    dataset['Cabin_number'] = dataset['Cabin'].apply(lambda x: x.split('/')[1]).astype(int)\n",
    "    dataset['Cabin_side'] = dataset['Cabin'].apply(lambda x: x.split('/')[2])\n",
    "\n",
    "    dataset.loc[dataset['Cabin_deck']=='Z', 'Cabin_deck']=np.nan\n",
    "    dataset.loc[dataset['Cabin_number']==9999, 'Cabin_number']=np.nan\n",
    "    dataset.loc[dataset['Cabin_side']=='Z', 'Cabin_side']=np.nan\n",
    "\n",
    "    dataset.drop('Cabin', axis=1, inplace=True)\n",
    "    mv_cabins(dataset)\n",
    "    mv_vip_crio(dataset)\n",
    "\n",
    "\n",
    "preprocess_data(train_x)\n",
    "preprocess_data(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Feature  Importance\n",
      "15   Expenditure    0.103269\n",
      "20  Cabin_number    0.072006\n",
      "0    PassengerId    0.070462\n",
      "9            Spa    0.066563\n",
      "11         Group    0.065693\n",
      "14       Surname    0.064711\n",
      "7      FoodCourt    0.062786\n",
      "10        VRDeck    0.060425\n",
      "4            Age    0.059240\n",
      "2      CryoSleep    0.058959\n",
      "16   No_spending    0.055042\n",
      "8   ShoppingMall    0.050822\n",
      "6    RoomService    0.049670\n",
      "19    Cabin_deck    0.039829\n",
      "1     HomePlanet    0.026782\n",
      "18     Age_group    0.022704\n",
      "21    Cabin_side    0.019293\n",
      "3    Destination    0.018012\n",
      "12    Group_size    0.013688\n",
      "17   Family_size    0.013156\n",
      "13          Solo    0.005624\n",
      "5            VIP    0.001265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "def feature_sel(dataset, label, fs, importance=0.03):\n",
    "    # Train the Random Forest model\n",
    "    dataset = dataset.apply(lambda col: col.astype(str) if col.dtype == 'object' else col)\n",
    "\n",
    "    # Seleziona le colonne numeriche e categoriali\n",
    "    num_cols = dataset.select_dtypes(exclude='object').columns\n",
    "    cat_cols = dataset.select_dtypes(include='object').columns\n",
    "\n",
    "    # Applica lo scaling ai dati numerici\n",
    "    scaler = StandardScaler()\n",
    "    dataset[num_cols] = scaler.fit_transform(dataset[num_cols])\n",
    "\n",
    "    # Applica l'encoding ai dati categoriali\n",
    "    encoder = OrdinalEncoder()\n",
    "    dataset[cat_cols] = encoder.fit_transform(dataset[cat_cols])\n",
    "    if fs:\n",
    "        # Train the Random Forest model\n",
    "        rf = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "        rf.fit(dataset, label)\n",
    "\n",
    "        # Extract feature importances\n",
    "        importances = rf.feature_importances_\n",
    "        feature_names = dataset.columns\n",
    "        feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "        # Rank features by importance\n",
    "        feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "        print(feature_importance_df)\n",
    "\n",
    "        # Select top N features (example selecting top 10 features)\n",
    "        top_features = feature_importance_df['Feature'][(feature_importance_df['Importance']>=importance)].values\n",
    "        return dataset[top_features]\n",
    "    return dataset\n",
    "\n",
    "train_x = feature_sel(train_x, train_y, True)\n",
    "val_x = feature_sel(val_x, train_y, False)\n",
    "val_x = val_x[train_x.columns]\n",
    "\n",
    "train_x = pd.get_dummies(train_x, columns=train_x.select_dtypes(include=['object', 'bool']).columns.difference(['Surname', 'Cabin_number']))\n",
    "val_x = pd.get_dummies(val_x, columns=val_x.select_dtypes(include=['object', 'bool']).columns.difference(['Surname', 'Cabin_number']))\n",
    "\n",
    "train_x = train_x.astype(float)\n",
    "train_y = train_y.astype(float)\n",
    "\n",
    "val_x = val_x.astype(float)\n",
    "val_y = val_y.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 20:18:02.677159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:18:02.677486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:18:02.677689: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:18:02.761828: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:18:02.762125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:18:02.762410: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-17 20:18:02.762576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1743 MB memory:  -> device: 0, name: NVIDIA GeForce MX230, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 14)                210       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 14)                56        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              15360     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 256)               1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 316683 (1.21 MB)\n",
      "Trainable params: 313839 (1.20 MB)\n",
      "Non-trainable params: 2844 (11.11 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 20:18:03.220037: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 20:18:07.175758: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7cbde4164f20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-17 20:18:07.175813: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce MX230, Compute Capability 6.1\n",
      "2024-09-17 20:18:07.183674: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-17 20:18:07.239709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-09-17 20:18:07.347593: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 40ms/step - loss: 0.6195 - accuracy: 0.5013 - val_loss: 6.8848 - val_accuracy: 0.4945\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3069 - accuracy: 0.5027 - val_loss: 1.1047 - val_accuracy: 0.4940\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2870 - accuracy: 0.5111 - val_loss: 0.3773 - val_accuracy: 0.4894\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2814 - accuracy: 0.5079 - val_loss: 0.2869 - val_accuracy: 0.4888\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2738 - accuracy: 0.5102 - val_loss: 0.2782 - val_accuracy: 0.4951\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2693 - accuracy: 0.5078 - val_loss: 0.2729 - val_accuracy: 0.4928\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2629 - accuracy: 0.5014 - val_loss: 0.2776 - val_accuracy: 0.4830\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2586 - accuracy: 0.5131 - val_loss: 0.2641 - val_accuracy: 0.4951\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2528 - accuracy: 0.5142 - val_loss: 0.2497 - val_accuracy: 0.4951\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2497 - accuracy: 0.5081 - val_loss: 0.2443 - val_accuracy: 0.4905\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2423 - accuracy: 0.5312 - val_loss: 0.2425 - val_accuracy: 0.4963\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2410 - accuracy: 0.5144 - val_loss: 0.2369 - val_accuracy: 0.4951\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2370 - accuracy: 0.5131 - val_loss: 0.2338 - val_accuracy: 0.4957\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2332 - accuracy: 0.5168 - val_loss: 0.2311 - val_accuracy: 0.4813\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2300 - accuracy: 0.5209 - val_loss: 0.2280 - val_accuracy: 0.4917\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2278 - accuracy: 0.5213 - val_loss: 0.2256 - val_accuracy: 0.4905\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2262 - accuracy: 0.5249 - val_loss: 0.2227 - val_accuracy: 0.4888\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2233 - accuracy: 0.5177 - val_loss: 0.2221 - val_accuracy: 0.4888\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2205 - accuracy: 0.5224 - val_loss: 0.2202 - val_accuracy: 0.4894\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2179 - accuracy: 0.5324 - val_loss: 0.2169 - val_accuracy: 0.4819\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2168 - accuracy: 0.5263 - val_loss: 0.2154 - val_accuracy: 0.4865\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2143 - accuracy: 0.5308 - val_loss: 0.2130 - val_accuracy: 0.5078\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2130 - accuracy: 0.5266 - val_loss: 0.2122 - val_accuracy: 0.4761\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2116 - accuracy: 0.5318 - val_loss: 0.2102 - val_accuracy: 0.5049\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2106 - accuracy: 0.5286 - val_loss: 0.2085 - val_accuracy: 0.4836\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2089 - accuracy: 0.5216 - val_loss: 0.2078 - val_accuracy: 0.4865\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2075 - accuracy: 0.5269 - val_loss: 0.2059 - val_accuracy: 0.4796\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2053 - accuracy: 0.5339 - val_loss: 0.2044 - val_accuracy: 0.5147\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2039 - accuracy: 0.5262 - val_loss: 0.2034 - val_accuracy: 0.4848\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2025 - accuracy: 0.5315 - val_loss: 0.2024 - val_accuracy: 0.4853\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2017 - accuracy: 0.5256 - val_loss: 0.2010 - val_accuracy: 0.4968\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2005 - accuracy: 0.5332 - val_loss: 0.2001 - val_accuracy: 0.4940\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2005 - accuracy: 0.5240 - val_loss: 0.1990 - val_accuracy: 0.5009\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1986 - accuracy: 0.5352 - val_loss: 0.1983 - val_accuracy: 0.4830\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1982 - accuracy: 0.5285 - val_loss: 0.1973 - val_accuracy: 0.4853\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1963 - accuracy: 0.5378 - val_loss: 0.1967 - val_accuracy: 0.4836\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1954 - accuracy: 0.5371 - val_loss: 0.1957 - val_accuracy: 0.5049\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1954 - accuracy: 0.5306 - val_loss: 0.1954 - val_accuracy: 0.5049\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1949 - accuracy: 0.5278 - val_loss: 0.1942 - val_accuracy: 0.4928\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1947 - accuracy: 0.5190 - val_loss: 0.1938 - val_accuracy: 0.4876\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1928 - accuracy: 0.5326 - val_loss: 0.1932 - val_accuracy: 0.4917\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1928 - accuracy: 0.5262 - val_loss: 0.1922 - val_accuracy: 0.4807\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1918 - accuracy: 0.5298 - val_loss: 0.1917 - val_accuracy: 0.4865\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1912 - accuracy: 0.5290 - val_loss: 0.1907 - val_accuracy: 0.5250\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1910 - accuracy: 0.5384 - val_loss: 0.1907 - val_accuracy: 0.5049\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1903 - accuracy: 0.5298 - val_loss: 0.1897 - val_accuracy: 0.5049\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1895 - accuracy: 0.5280 - val_loss: 0.1900 - val_accuracy: 0.4951\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1896 - accuracy: 0.5345 - val_loss: 0.1891 - val_accuracy: 0.4980\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1887 - accuracy: 0.5278 - val_loss: 0.1893 - val_accuracy: 0.4951\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1880 - accuracy: 0.5237 - val_loss: 0.1891 - val_accuracy: 0.4951\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1882 - accuracy: 0.5240 - val_loss: 0.1885 - val_accuracy: 0.4951\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1873 - accuracy: 0.5253 - val_loss: 0.1871 - val_accuracy: 0.4836\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1866 - accuracy: 0.5342 - val_loss: 0.1888 - val_accuracy: 0.4951\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1862 - accuracy: 0.5324 - val_loss: 0.1877 - val_accuracy: 0.4951\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1858 - accuracy: 0.5305 - val_loss: 0.1863 - val_accuracy: 0.4905\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1859 - accuracy: 0.5309 - val_loss: 0.1858 - val_accuracy: 0.4819\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1862 - accuracy: 0.5220 - val_loss: 0.1855 - val_accuracy: 0.4888\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1842 - accuracy: 0.5351 - val_loss: 0.1856 - val_accuracy: 0.4784\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1849 - accuracy: 0.5347 - val_loss: 0.1845 - val_accuracy: 0.4514\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1846 - accuracy: 0.5312 - val_loss: 0.1842 - val_accuracy: 0.4842\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1838 - accuracy: 0.5336 - val_loss: 0.1873 - val_accuracy: 0.4951\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1836 - accuracy: 0.5344 - val_loss: 0.1842 - val_accuracy: 0.4951\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1834 - accuracy: 0.5239 - val_loss: 0.1868 - val_accuracy: 0.4945\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 0.5311 - val_loss: 0.1841 - val_accuracy: 0.4905\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1823 - accuracy: 0.5398 - val_loss: 0.1839 - val_accuracy: 0.4899\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1823 - accuracy: 0.5295 - val_loss: 0.1835 - val_accuracy: 0.4951\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.1822 - accuracy: 0.5269 - val_loss: 0.1821 - val_accuracy: 0.4842\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1816 - accuracy: 0.5285 - val_loss: 0.1837 - val_accuracy: 0.4951\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1813 - accuracy: 0.5279 - val_loss: 0.1849 - val_accuracy: 0.4951\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1809 - accuracy: 0.5433 - val_loss: 0.1817 - val_accuracy: 0.4945\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1791 - accuracy: 0.5677 - val_loss: 0.1816 - val_accuracy: 0.5014\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1759 - accuracy: 0.5922 - val_loss: 0.1953 - val_accuracy: 0.5049\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1814 - accuracy: 0.5460 - val_loss: 0.1865 - val_accuracy: 0.5049\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1824 - accuracy: 0.5278 - val_loss: 0.1825 - val_accuracy: 0.5049\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1805 - accuracy: 0.5470 - val_loss: 0.1832 - val_accuracy: 0.5049\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1766 - accuracy: 0.5943 - val_loss: 0.1946 - val_accuracy: 0.5049\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1744 - accuracy: 0.6142 - val_loss: 0.1867 - val_accuracy: 0.5049\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1822 - accuracy: 0.5454 - val_loss: 0.1919 - val_accuracy: 0.4951\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1805 - accuracy: 0.5440 - val_loss: 0.1862 - val_accuracy: 0.4957\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1783 - accuracy: 0.5634 - val_loss: 0.1821 - val_accuracy: 0.5216\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1663 - accuracy: 0.6425 - val_loss: 0.1833 - val_accuracy: 0.5083\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1585 - accuracy: 0.7025 - val_loss: 0.2019 - val_accuracy: 0.5066\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1567 - accuracy: 0.6993 - val_loss: 0.1863 - val_accuracy: 0.5072\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1436 - accuracy: 0.7371 - val_loss: 0.2295 - val_accuracy: 0.5066\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1426 - accuracy: 0.7478 - val_loss: 0.2353 - val_accuracy: 0.5055\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1385 - accuracy: 0.7448 - val_loss: 0.2352 - val_accuracy: 0.5055\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1455 - accuracy: 0.7317 - val_loss: 0.1952 - val_accuracy: 0.5066\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1402 - accuracy: 0.7400 - val_loss: 0.1752 - val_accuracy: 0.5233\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1376 - accuracy: 0.7443 - val_loss: 0.1762 - val_accuracy: 0.5296\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1353 - accuracy: 0.7504 - val_loss: 0.1780 - val_accuracy: 0.5152\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1356 - accuracy: 0.7436 - val_loss: 0.1727 - val_accuracy: 0.5446\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1340 - accuracy: 0.7498 - val_loss: 0.1746 - val_accuracy: 0.5210\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1337 - accuracy: 0.7498 - val_loss: 0.1756 - val_accuracy: 0.5233\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1312 - accuracy: 0.7617 - val_loss: 0.1731 - val_accuracy: 0.5331\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1303 - accuracy: 0.7537 - val_loss: 0.1674 - val_accuracy: 0.5842\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1340 - accuracy: 0.7521 - val_loss: 0.1712 - val_accuracy: 0.5342\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1387 - accuracy: 0.7435 - val_loss: 0.1705 - val_accuracy: 0.7389\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1337 - accuracy: 0.7527 - val_loss: 0.1615 - val_accuracy: 0.7470\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1313 - accuracy: 0.7557 - val_loss: 0.1696 - val_accuracy: 0.7320\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1315 - accuracy: 0.7578 - val_loss: 0.1640 - val_accuracy: 0.7556\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1294 - accuracy: 0.7586 - val_loss: 0.1675 - val_accuracy: 0.6803\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.1327 - accuracy: 0.7561 - val_loss: 0.1626 - val_accuracy: 0.6486\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1332 - accuracy: 0.7567 - val_loss: 0.1647 - val_accuracy: 0.6285\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1307 - accuracy: 0.7580 - val_loss: 0.1613 - val_accuracy: 0.6665\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1332 - accuracy: 0.7514 - val_loss: 0.1643 - val_accuracy: 0.7113\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1304 - accuracy: 0.7555 - val_loss: 0.1505 - val_accuracy: 0.7648\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1297 - accuracy: 0.7575 - val_loss: 0.1590 - val_accuracy: 0.6682\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1333 - accuracy: 0.7476 - val_loss: 0.1562 - val_accuracy: 0.7401\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1298 - accuracy: 0.7571 - val_loss: 0.1519 - val_accuracy: 0.7573\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1287 - accuracy: 0.7571 - val_loss: 0.1477 - val_accuracy: 0.7625\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1285 - accuracy: 0.7614 - val_loss: 0.1610 - val_accuracy: 0.5946\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1280 - accuracy: 0.7548 - val_loss: 0.1503 - val_accuracy: 0.7734\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1285 - accuracy: 0.7501 - val_loss: 0.1581 - val_accuracy: 0.6532\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1281 - accuracy: 0.7620 - val_loss: 0.1466 - val_accuracy: 0.7527\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1280 - accuracy: 0.7607 - val_loss: 0.1534 - val_accuracy: 0.6791\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1295 - accuracy: 0.7541 - val_loss: 0.1494 - val_accuracy: 0.7464\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1274 - accuracy: 0.7611 - val_loss: 0.1533 - val_accuracy: 0.7660\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1264 - accuracy: 0.7637 - val_loss: 0.1476 - val_accuracy: 0.7545\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1275 - accuracy: 0.7591 - val_loss: 0.1520 - val_accuracy: 0.6458\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1262 - accuracy: 0.7581 - val_loss: 0.1456 - val_accuracy: 0.7637\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1275 - accuracy: 0.7567 - val_loss: 0.1428 - val_accuracy: 0.7625\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1302 - accuracy: 0.7563 - val_loss: 0.1485 - val_accuracy: 0.7614\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1295 - accuracy: 0.7587 - val_loss: 0.1387 - val_accuracy: 0.7671\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1281 - accuracy: 0.7581 - val_loss: 0.1455 - val_accuracy: 0.7717\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1262 - accuracy: 0.7601 - val_loss: 0.1423 - val_accuracy: 0.7711\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1264 - accuracy: 0.7620 - val_loss: 0.1406 - val_accuracy: 0.7596\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1274 - accuracy: 0.7548 - val_loss: 0.1370 - val_accuracy: 0.7349\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1250 - accuracy: 0.7568 - val_loss: 0.1372 - val_accuracy: 0.7740\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1278 - accuracy: 0.7554 - val_loss: 0.1413 - val_accuracy: 0.7292\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1286 - accuracy: 0.7551 - val_loss: 0.1308 - val_accuracy: 0.7665\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1263 - accuracy: 0.7613 - val_loss: 0.1412 - val_accuracy: 0.7119\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1267 - accuracy: 0.7551 - val_loss: 0.1355 - val_accuracy: 0.7401\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1258 - accuracy: 0.7634 - val_loss: 0.1372 - val_accuracy: 0.7240\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1254 - accuracy: 0.7581 - val_loss: 0.1270 - val_accuracy: 0.7763\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1291 - accuracy: 0.7561 - val_loss: 0.1380 - val_accuracy: 0.6912\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1296 - accuracy: 0.7588 - val_loss: 0.1258 - val_accuracy: 0.7803\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1273 - accuracy: 0.7557 - val_loss: 0.1366 - val_accuracy: 0.7389\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1275 - accuracy: 0.7619 - val_loss: 0.1319 - val_accuracy: 0.7608\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1270 - accuracy: 0.7597 - val_loss: 0.1395 - val_accuracy: 0.7309\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1315 - accuracy: 0.7511 - val_loss: 0.1317 - val_accuracy: 0.7665\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1271 - accuracy: 0.7624 - val_loss: 0.1313 - val_accuracy: 0.7654\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1270 - accuracy: 0.7548 - val_loss: 0.1350 - val_accuracy: 0.7602\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1269 - accuracy: 0.7657 - val_loss: 0.1247 - val_accuracy: 0.7711\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1274 - accuracy: 0.7575 - val_loss: 0.1385 - val_accuracy: 0.7510\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1256 - accuracy: 0.7637 - val_loss: 0.1253 - val_accuracy: 0.7757\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1250 - accuracy: 0.7630 - val_loss: 0.1320 - val_accuracy: 0.7516\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1247 - accuracy: 0.7633 - val_loss: 0.1262 - val_accuracy: 0.7734\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1261 - accuracy: 0.7584 - val_loss: 0.1268 - val_accuracy: 0.7729\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1252 - accuracy: 0.7649 - val_loss: 0.1300 - val_accuracy: 0.7688\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1252 - accuracy: 0.7657 - val_loss: 0.1304 - val_accuracy: 0.7556\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1245 - accuracy: 0.7626 - val_loss: 0.1302 - val_accuracy: 0.7602\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1251 - accuracy: 0.7586 - val_loss: 0.1290 - val_accuracy: 0.7602\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1242 - accuracy: 0.7672 - val_loss: 0.1248 - val_accuracy: 0.7734\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1254 - accuracy: 0.7599 - val_loss: 0.1326 - val_accuracy: 0.7550\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1262 - accuracy: 0.7675 - val_loss: 0.1238 - val_accuracy: 0.7780\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1253 - accuracy: 0.7613 - val_loss: 0.1265 - val_accuracy: 0.7740\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1242 - accuracy: 0.7624 - val_loss: 0.1278 - val_accuracy: 0.7642\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1240 - accuracy: 0.7668 - val_loss: 0.1287 - val_accuracy: 0.7746\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1253 - accuracy: 0.7650 - val_loss: 0.1299 - val_accuracy: 0.7533\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1236 - accuracy: 0.7611 - val_loss: 0.1323 - val_accuracy: 0.7441\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1227 - accuracy: 0.7665 - val_loss: 0.1346 - val_accuracy: 0.7608\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1257 - accuracy: 0.7593 - val_loss: 0.1246 - val_accuracy: 0.7683\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1301 - accuracy: 0.7601 - val_loss: 0.1288 - val_accuracy: 0.7602\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1265 - accuracy: 0.7571 - val_loss: 0.1239 - val_accuracy: 0.7757\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1247 - accuracy: 0.7656 - val_loss: 0.1386 - val_accuracy: 0.7165\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1250 - accuracy: 0.7613 - val_loss: 0.1283 - val_accuracy: 0.7729\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1257 - accuracy: 0.7554 - val_loss: 0.1320 - val_accuracy: 0.7625\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1242 - accuracy: 0.7670 - val_loss: 0.1272 - val_accuracy: 0.7746\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.1248 - accuracy: 0.7619 - val_loss: 0.1402 - val_accuracy: 0.7303\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1239 - accuracy: 0.7619 - val_loss: 0.1340 - val_accuracy: 0.7527\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1251 - accuracy: 0.7630 - val_loss: 0.1306 - val_accuracy: 0.7545\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1238 - accuracy: 0.7611 - val_loss: 0.1263 - val_accuracy: 0.7700\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1228 - accuracy: 0.7657 - val_loss: 0.1271 - val_accuracy: 0.7608\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.1252 - accuracy: 0.7617 - val_loss: 0.1284 - val_accuracy: 0.7568\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.1252 - accuracy: 0.7594 - val_loss: 0.1282 - val_accuracy: 0.7614\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 49\u001b[0m\n\u001b[1;32m     41\u001b[0m early_stopping_cb \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_x, train_y,\n\u001b[1;32m     44\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mEPOCHS,\n\u001b[1;32m     45\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[1;32m     46\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[early_stopping_cb],\n\u001b[1;32m     47\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(val_x, val_y))\n\u001b[0;32m---> 49\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialising the NN\n",
    "\n",
    "model = Sequential()\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 750\n",
    "DROPOUT = 0.1\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# layers\n",
    "model.add(Dense(train_x.shape[-1], kernel_initializer = HeUniform(), activation = 'relu', input_dim = train_x.shape[-1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(1024, kernel_initializer = HeUniform(), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(256, kernel_initializer = HeUniform(), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(128, kernel_initializer = HeUniform(), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(DROPOUT))\n",
    "model.add(Dense(1, kernel_initializer = GlorotUniform(), activation = 'sigmoid'))\n",
    "\n",
    "# summary\n",
    "model.summary()\n",
    "# Compiling the NN\n",
    "initial_learning_rate = 0.01\n",
    "final_learning_rate = 0.0001\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate)**(1/EPOCHS)\n",
    "steps_per_epoch = int(train_x.shape[0]/BATCH_SIZE)\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=learning_rate_decay_factor,\n",
    "    staircase=True)\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=lr_schedule), loss = 'binary_focal_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the NN\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=[early_stopping_cb],\n",
    "                    validation_data=(val_x, val_y))\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.legend(['val_accuracy', 'accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the NN\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import HeUniform\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "model = Sequential()\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 512\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# layers\n",
    "model.add(Dense(train_x.shape[-1]*2, kernel_initializer = HeUniform(), activation = 'relu', input_dim = train_x.shape[-1]))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(16, kernel_initializer = HeUniform(), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
    "model.add(Dense(32, kernel_initializer = HeUniform(), activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(30e-6)))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(64, kernel_initializer = HeUniform(), activation = 'relu'))\n",
    "#model.add(Dense(128, kernel_initializer = HeUniform(), activation = 'relu'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, kernel_initializer = GlorotUniform(), activation = 'sigmoid'))\n",
    "\n",
    "# summary\n",
    "model.summary()\n",
    "# Compiling the NN\n",
    "initial_learning_rate = 0.001\n",
    "final_learning_rate = 0.0001\n",
    "learning_rate_decay_factor = (final_learning_rate / initial_learning_rate)**(1/EPOCHS)\n",
    "steps_per_epoch = int(train_x.shape[0]/BATCH_SIZE)\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=steps_per_epoch,\n",
    "    decay_rate=learning_rate_decay_factor,\n",
    "    staircase=True)\n",
    "model.compile(optimizer = keras.optimizers.Adam(learning_rate=lr_schedule), loss = 'binary_focal_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the NN\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=[early_stopping_cb],\n",
    "                    validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stampare il grafico dell'accuracy e della loss tra tarining e validation\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "# aggiungere una legenda\n",
    "plt.legend(['val_accuracy', 'accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import HeNormal, GlorotUniform\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(units=train_x.shape[-1], activation=\"relu\", input_shape=(train_x.shape[-1],), kernel_initializer=GlorotUniform()),\n",
    "        keras.layers.Dense(units=128, activation=\"relu\", kernel_initializer=HeNormal()),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=64, activation=\"relu\", kernel_initializer=HeNormal()),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(units=64, activation=\"relu\", kernel_initializer=HeNormal()),\n",
    "        keras.layers.Dense(units=32, activation=\"relu\", kernel_initializer=HeNormal()),\n",
    "        keras.layers.Dense(units=1, activation=\"sigmoid\", kernel_initializer=GlorotUniform()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta = 0.0002, # minimium amount of change to count as an improvement\n",
    "    patience  = 20,     # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "history = model.fit(train_x, train_y,\n",
    "          epochs=500,\n",
    "          batch_size=512,\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=(val_x, val_y))\n",
    "\n",
    "logs = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
