{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "/home/ella/Documents/FL/venv-federated/lib/python3.9/site-packages/tensorflow_federated\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys \n",
    "import matplotlib \n",
    "import scipy as sp \n",
    "import IPython\n",
    "from IPython import display \n",
    "import sklearn \n",
    "import random\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLIENTS = 5\n",
    "ACTIVE_CLIENTS = 5\n",
    "BATCH_SIZE = 5\n",
    "path = os.path.dirname(tff.__file__)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibili:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow sta usando la GPU\n"
     ]
    }
   ],
   "source": [
    "# Lista delle GPU disponibili\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs disponibili: \", gpus)\n",
    "\n",
    "# Verifica se TensorFlow utilizza la GPU\n",
    "if gpus:\n",
    "    print(\"TensorFlow sta usando la GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow non sta usando la GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "train_df = pd.read_csv('datasets/train.csv')\n",
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "# Viene diviso il train set in train e validation set\n",
    "train_df, val_df = train_test_split(train_df, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "train_x = train_df.iloc[:,1:].to_numpy()\n",
    "train_y = train_df.iloc[:,0].to_numpy()\n",
    "\n",
    "val_x = val_df.iloc[:,1:].to_numpy()\n",
    "val_y = val_df.iloc[:,0].to_numpy()\n",
    "\n",
    "test_x = test_df.iloc[:,1:].to_numpy()\n",
    "test_y = test_df.iloc[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare la dipendenza tra feature categoriche con il chi-square test.\n",
    "# Il test ha come ipotesi nulla che le due variabili siano indipendenti. Quindi con un p-value\n",
    "# minore di 0.05 si rigetta l'ipotesi nulla e si accetta che le due variabili sono dipendenti.\n",
    "def chi_square(f1, f2):\n",
    "    crosstab_result=pd.crosstab(index=f1,columns=f2)\n",
    "    return chi2_contingency(crosstab_result)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategia: Home_planet\n",
    "# Si nota la forte correlazione tra group ed home planet/destination e quindi per i nan si possono assegnre i valori del gruppo\n",
    "# (che saranno uguali alla moda). Restano problematici i gruppi composti da una sola persona, si introduce quindi una nuova categoria\n",
    "# di home planet e destination per persona con origine o destinazione sconosciuta.\n",
    "\n",
    "def mv_hp_d(dataset):\n",
    "    print(\"-------------------------- HomePlanet -------------------------\")\n",
    "\n",
    "    # HomePlanet\n",
    "    p = chi_square(dataset['HomePlanet'], dataset['Group'])\n",
    "    print(f\"Le feature HomePlanet e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                           else \"Le feature Destination e Group non sono correlate\")\n",
    "\n",
    "    print(f\"Numero di persone con HomePlanet nullo: {str(dataset['HomePlanet'].isna().sum())}\")\n",
    "    dataset['HomePlanet'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['HomePlanet'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['HomePlanet'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['HomePlanet'].transform(lambda x: x.fillna(\"unknown\"))\n",
    "    print(f\"Numero di persone con HomePlanet nullo: {str(dataset['HomePlanet'].isna().sum())}\")\n",
    "\n",
    "    # Destination\n",
    "    print(\"-------------------------- Destination ------------------------\")\n",
    "    p = chi_square(dataset['Destination'], dataset['Group'])\n",
    "    print(f\"Le feature Destination e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                           else \"Le feature Destination e Group non sono correlate\")\n",
    "    \n",
    "    print(f\"Numero di persone con Destination nullo: {str(dataset['Destination'].isna().sum())}\")\n",
    "    dataset['Destination'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Destination'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Destination'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['Destination'].transform(lambda x: x.fillna(\"unknown\"))\n",
    "    print(f\"Numero di persone con Destination nullo: {str(dataset['Destination'].isna().sum())}\")\n",
    "\n",
    "# Strategia: Age\n",
    "# Si distinguono 3 casi di persone con Age nullo: persone sole, persone con famiglia che non spendono e persone con famiglia che spendono.\n",
    "# Per assegnare l'età si usa la mediana del caso di appartenenza, immaginando che è meno probabile che una persona sola sia un bambino\n",
    "# e che al contrario è più probabile che una persona che non spende, ma è in un gruppo lo sia.\n",
    "def mv_age(dataset):\n",
    "    print(\"----------------------------- Age -----------------------------\")\n",
    "    solo = dataset['Solo']==1\n",
    "    family_no_spending = (dataset['Family_size']>1) & (dataset['No_spending']==1)\n",
    "    family_spending = (dataset['Family_size']>1) & (dataset['No_spending']==0)\n",
    "    \n",
    "    print(f\"Numero di persone con Age nullo: {str(dataset['Age'].isna().sum())}, di cui:\")\n",
    "    print(f\"Persone sole: {str(dataset['Age'][solo].isna().sum())}\")\n",
    "    print(f\"Persone con famiglia che non spendono: {str(dataset['Age'][family_no_spending].isna().sum())}\")   \n",
    "    print(f\"Persone con famiglia che spendono: {str(dataset['Age'][family_spending].isna().sum())}\")\n",
    "\n",
    "    dataset['Age'][solo] = dataset[solo]['Age'].transform(lambda x: x.fillna(dataset[solo]['Age'].median()))\n",
    "    dataset['Age'][family_no_spending] = dataset[family_no_spending]['Age'].transform(lambda x: x.fillna(dataset[family_no_spending]['Age'].median()))\n",
    "    dataset['Age'][family_spending] = dataset[family_spending]['Age'].transform(lambda x: x.fillna(dataset[family_spending]['Age'].median()))\n",
    "\n",
    "    print(f\"Numero di persone con Age nullo: {str(dataset['Age'].isna().sum())}\")   \n",
    "\n",
    "\n",
    "# Strategia: Surname\n",
    "# Si osserva che i gruppi sono per gran parte composti da persone con lo stesso cognome, quindi si può assegnare la moda del cognome del gruppo\n",
    "# alle persone con cognome nullo. Per i gruppi composti da una sola persona si assegna cognome 'unknown'.\n",
    "def mv_surname(dataset):\n",
    "    print(\"------------------------------ Surname ------------------------\")\n",
    "\n",
    "    p = chi_square(dataset['Surname'], dataset['Group'])\n",
    "    print(f\"Le feature Surname e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                       else \"Le feature Surname e Group non sono correlate\")\n",
    "\n",
    "    print(f\"Numero di persone con Surname nullo: {str(dataset['Surname'].isna().sum())}\")\n",
    "    dataset['Surname'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Surname'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Surname'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['Surname'].transform(lambda x: x.fillna(\"Unknown\"))\n",
    "    print(f\"Numero di persone con Surname nullo: {str(dataset['Surname'].isna().sum())}\")\n",
    "\n",
    "# Strategia: RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "# Si sostituiscono i valori nulli con la media di spesa delle altre categorie non nulle, dopo aver osservato che ogni persona ha almeno un valore\n",
    "# di spesa non nullo. Ad esempio, se una persona ha spesa nulla per RoomService e ShoppingMall, ma ha spesa per FoodCourt e Spa, si assegna la media\n",
    "# di FoodCourt e Spa per RoomService e ShoppingMall.\n",
    "def mv_exp(dataset):\n",
    "    print(\"------ RoomService, FoodCourt, ShoppingMall, Spa, VRDeck ------\")\n",
    "    print(f\"Persone con servizi nulli: {str(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].isnull().any(axis=1).sum())}\")\n",
    "    # Per ogni persona con almeno un servizio nullo, si calcola la media delle spese non nulle\n",
    "    dataset['RoomService'] = dataset['RoomService'].fillna(dataset[['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['FoodCourt'] = dataset['FoodCourt'].fillna(dataset[['RoomService', 'ShoppingMall', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['ShoppingMall'] = dataset['ShoppingMall'].fillna(dataset[['RoomService', 'FoodCourt', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['Spa'] = dataset['Spa'].fillna(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'VRDeck']].mean(axis=1))\n",
    "    dataset['VRDeck'] = dataset['VRDeck'].fillna(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa']].mean(axis=1))\n",
    "    print(f\"Persone con servizi nulli: {str(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].isnull().any(axis=1).sum())}\")\n",
    "\n",
    "# Controllare se i gruppi hanno tutti lo stesso valore di cabin_side\n",
    "def mv_cabins(dataset):\n",
    "    print(\"------------------------- Cabin_side --------------------------\")\n",
    "    p = chi_square(dataset['Cabin_side'], dataset['Group'])\n",
    "    print(f\"Le feature Cabin_side e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                          else \"Le feature Cabin_side e Group non sono correlate\")\n",
    "    print(f\"Numero di persone con Cabin_side nullo: {str(dataset['Cabin_side'].isna().sum())}\")\n",
    "    dataset['Cabin_side'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Cabin_side'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Cabin_side'][(dataset['Solo']==1)] = dataset['Cabin_side'][(dataset['Solo']==1)].fillna('unknown')\n",
    "    print(f\"Numero di persone con Cabin_side nullo: {str(dataset['Cabin_side'].isna().sum())}\")\n",
    "\n",
    "    print(\"------------------------ Cabin_number -------------------------\")\n",
    "    p = chi_square(dataset['Cabin_number'], dataset['Group'])\n",
    "    print(f\"Le feature Cabin_number e Group sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                            else \"Le feature Cabin_number e Group non sono correlate\")\n",
    "    print(f\"Numero di persone con Cabin_number nullo: {str(dataset['Cabin_number'].isna().sum())}\")\n",
    "    dataset['Cabin_number'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Cabin_number'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Cabin_number'][(dataset['Solo']==1)] = dataset['Cabin_number'][(dataset['Solo']==1)].fillna('unknown')\n",
    "    print(f\"Numero di persone con Cabin_number nullo: {str(dataset['Cabin_number'].isna().sum())}\")\n",
    "    \n",
    "    print(\"------------------------- Cabin_deck --------------------------\")\n",
    "    p = chi_square(dataset['Cabin_deck'], dataset['HomePlanet'])\n",
    "    print(f\"Le feature Cabin_deck e HomePlanet sono correlate, con p-value{p}\" if p < 0.05 \\\n",
    "                                                                               else \"Le feature Cabin_deck e HomePlanet non sono correlate\")\n",
    "    print(f\"Numero di persone con Cabin_deck nullo: {str(dataset['Cabin_deck'].isna().sum())}\")\n",
    "    dataset['Cabin_deck'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('HomePlanet')['Cabin_deck'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Cabin_deck'][(dataset['Solo']==1)] = dataset['Cabin_deck'][(dataset['Solo']==1)].fillna('unknown')\n",
    "    print(f\"Numero di persone con Cabin_deck nullo: {str(dataset['Cabin_deck'].isna().sum())}\")\n",
    "\n",
    "# Strategia: VIP, CrioSleep\n",
    "# Per le feature VIP e CrioSleep si assegna il valore della moda a tutti i valori nulli.\n",
    "def mv_vip_crio(dataset):\n",
    "    print(\"----------------------------- VIP, CryoSleep ------------------\")\n",
    "    print(f\"Numero di persone con VIP nullo: {str(dataset['VIP'].isna().sum())}\")\n",
    "    dataset['VIP'] = dataset['VIP'].fillna(dataset['VIP'].mode()[0])\n",
    "    print(f\"Numero di persone con VIP nullo: {str(dataset['VIP'].isna().sum())}\")\n",
    "\n",
    "    print(f\"Numero di persone con CryoSleep nullo: {str(dataset['CryoSleep'].isna().sum())}\")\n",
    "    dataset['CryoSleep'] = dataset['CryoSleep'].fillna(dataset['CryoSleep'].mode()[0])\n",
    "    print(f\"Numero di persone con CryoSleep nullo: {str(dataset['CryoSleep'].isna().sum())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ RoomService, FoodCourt, ShoppingMall, Spa, VRDeck ------\n",
      "Persone con servizi nulli: 691\n",
      "Persone con servizi nulli: 0\n",
      "-------------------------- HomePlanet -------------------------\n",
      "Le feature HomePlanet e Group sono correlate, con p-value7.383208949075836e-101\n",
      "Numero di persone con HomePlanet nullo: 168\n",
      "Numero di persone con HomePlanet nullo: 0\n",
      "-------------------------- Destination ------------------------\n",
      "Le feature Destination e Group sono correlate, con p-value0.00016495054761429579\n",
      "Numero di persone con Destination nullo: 139\n",
      "Numero di persone con Destination nullo: 0\n",
      "------------------------------ Surname ------------------------\n",
      "Le feature Surname e Group sono correlate, con p-value0.0\n",
      "Numero di persone con Surname nullo: 159\n",
      "Numero di persone con Surname nullo: 0\n",
      "----------------------------- Age -----------------------------\n",
      "Numero di persone con Age nullo: 148, di cui:\n",
      "Persone sole: 87\n",
      "Persone con famiglia che non spendono: 40\n",
      "Persone con famiglia che spendono: 21\n",
      "Numero di persone con Age nullo: 0\n",
      "------------------------- Cabin_side --------------------------\n",
      "Le feature Cabin_side e Group sono correlate, con p-value3.8625169822992095e-51\n",
      "Numero di persone con Cabin_side nullo: 158\n",
      "Numero di persone con Cabin_side nullo: 0\n",
      "------------------------ Cabin_number -------------------------\n",
      "Le feature Cabin_number e Group sono correlate, con p-value0.0\n",
      "Numero di persone con Cabin_number nullo: 158\n",
      "Numero di persone con Cabin_number nullo: 0\n",
      "------------------------- Cabin_deck --------------------------\n",
      "Le feature Cabin_deck e HomePlanet sono correlate, con p-value0.0\n",
      "Numero di persone con Cabin_deck nullo: 158\n",
      "Numero di persone con Cabin_deck nullo: 0\n",
      "----------------------------- VIP, CryoSleep ------------------\n",
      "Numero di persone con VIP nullo: 162\n",
      "Numero di persone con VIP nullo: 0\n",
      "Numero di persone con CryoSleep nullo: 177\n",
      "Numero di persone con CryoSleep nullo: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_data(dataset):\n",
    "    # Viene aggiunta una colonna per contare il numero di persone nel gruppo di appartenenza e se la persona è da sola\n",
    "    dataset['Group'] = dataset['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "    dataset['Group_size']=dataset['Group'].map(lambda x: dataset['Group'].value_counts()[x])\n",
    "    dataset['Solo']=(dataset['Group_size']==1).astype(int)\n",
    "\n",
    "    # Viene creata una colonna per il cognome e si rimuove la colonna Name\n",
    "    dataset['Name'].fillna('Unknown Unknown', inplace=True)\n",
    "    dataset['Surname']=dataset['Name'].str.split().str[-1]\n",
    "    dataset.loc[dataset['Surname']=='Unknown','Surname']=np.nan\n",
    "    dataset.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "    # Vengono riempiti i valori nulli delle colonne RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "    mv_exp(dataset)\n",
    "    \n",
    "    # Vengono prese tutte le colonne che rappresentano le spese e si aggiunge una colonna per contare il\n",
    "    # totale speso dalla persona e una colonna booleana per indicare se la persona non ha speso nulla\n",
    "    exp_feats=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    dataset['Expenditure']=dataset[exp_feats].sum(axis=1)\n",
    "    dataset['No_spending']=(dataset['Expenditure']==0).astype(int)\n",
    "\n",
    "    # Vengono riempiti i valori nulli della colonna HomePlanet, Destination, Surmane\n",
    "    mv_hp_d(dataset)\n",
    "    mv_surname(dataset)\n",
    "\n",
    "    # Viene aggiunta una colonna per contare le persone che hanno lo stesso cognome\n",
    "    dataset['Family_size']=dataset[(dataset['Surname']!='Unknown')].groupby('Group')['Surname'].transform('count')\n",
    "    dataset.loc[dataset['Surname']=='Unknown','Family_size']=1\n",
    "    dataset.loc[dataset['Family_size']>100,'Family_size']=np.nan\n",
    "\n",
    "    # Vengono riempiti i valori nulli della colonna Age\n",
    "    mv_age(dataset)\n",
    "\n",
    "\n",
    "    # Viene aggiunta una colonna che assegna ogni passeggero al gruppo di età di appartenenza\n",
    "    dataset['Age_group']=0\n",
    "    dataset.loc[dataset['Age']<=12,'Age_group']='Age_0-12'\n",
    "    dataset.loc[(dataset['Age']>12) & (dataset['Age']<18),'Age_group']='Age_13-17'\n",
    "    dataset.loc[(dataset['Age']>=18) & (dataset['Age']<=25),'Age_group']='Age_18-25'\n",
    "    dataset.loc[(dataset['Age']>25) & (dataset['Age']<=30),'Age_group']='Age_26-30'\n",
    "    dataset.loc[(dataset['Age']>30) & (dataset['Age']<=50),'Age_group']='Age_31-50'\n",
    "    dataset.loc[dataset['Age']>50,'Age_group']='Age_51+'\n",
    "\n",
    "    # Separazione della colonna 'Cabin' nelle colonne deck, number e side\n",
    "    dataset['Cabin'].fillna('Z/9999/Z', inplace=True)\n",
    "\n",
    "    dataset['Cabin_deck'] = dataset['Cabin'].apply(lambda x: x.split('/')[0])\n",
    "    dataset['Cabin_number'] = dataset['Cabin'].apply(lambda x: x.split('/')[1]).astype(int)\n",
    "    dataset['Cabin_side'] = dataset['Cabin'].apply(lambda x: x.split('/')[2])\n",
    "\n",
    "    dataset.loc[dataset['Cabin_deck']=='Z', 'Cabin_deck']=np.nan\n",
    "    dataset.loc[dataset['Cabin_number']==9999, 'Cabin_number']=np.nan\n",
    "    dataset.loc[dataset['Cabin_side']=='Z', 'Cabin_side']=np.nan\n",
    "\n",
    "    dataset.drop('Cabin', axis=1, inplace=True)\n",
    "    mv_cabins(dataset)\n",
    "    mv_vip_crio(dataset)\n",
    "\n",
    "\n",
    "preprocess_data(train_df)\n",
    "#preprocess_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId     0\n",
      "HomePlanet      0\n",
      "CryoSleep       0\n",
      "Destination     0\n",
      "Age             0\n",
      "VIP             0\n",
      "RoomService     0\n",
      "FoodCourt       0\n",
      "ShoppingMall    0\n",
      "Spa             0\n",
      "VRDeck          0\n",
      "Transported     0\n",
      "Group           0\n",
      "Group_size      0\n",
      "Solo            0\n",
      "Surname         0\n",
      "Expenditure     0\n",
      "No_spending     0\n",
      "Family_size     0\n",
      "Age_group       0\n",
      "Cabin_deck      0\n",
      "Cabin_number    0\n",
      "Cabin_side      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stampare le colonne con i valori nulli\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
