{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "/home/ella/Desktop/Progetto/venv-federated/lib/python3.9/site-packages/tensorflow_federated\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_federated as tff\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys \n",
    "import matplotlib \n",
    "import scipy as sp \n",
    "import IPython\n",
    "from IPython import display \n",
    "import sklearn \n",
    "import random\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "NUM_CLIENTS = 5\n",
    "ACTIVE_CLIENTS = 5\n",
    "BATCH_SIZE = 5\n",
    "path = os.path.dirname(tff.__file__)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs disponibili:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow sta usando la GPU\n"
     ]
    }
   ],
   "source": [
    "# Lista delle GPU disponibili\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs disponibili: \", gpus)\n",
    "\n",
    "# Verifica se TensorFlow utilizza la GPU\n",
    "if gpus:\n",
    "    print(\"TensorFlow sta usando la GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow non sta usando la GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Viene diviso il train set in train e validation set\n",
    "train_df, val_df = train_test_split(train_df, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "train_x = train_df.iloc[:,1:].to_numpy()\n",
    "train_y = train_df.iloc[:,0].to_numpy()\n",
    "\n",
    "val_x = val_df.iloc[:,1:].to_numpy()\n",
    "val_y = val_df.iloc[:,0].to_numpy()\n",
    "\n",
    "test_x = test_df.iloc[:,1:].to_numpy()\n",
    "test_y = test_df.iloc[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      object\n",
      "HomePlanet       object\n",
      "CryoSleep        object\n",
      "Cabin            object\n",
      "Destination      object\n",
      "Age             float64\n",
      "VIP              object\n",
      "RoomService     float64\n",
      "FoodCourt       float64\n",
      "ShoppingMall    float64\n",
      "Spa             float64\n",
      "VRDeck          float64\n",
      "Name             object\n",
      "Transported        bool\n",
      "dtype: object\n",
      "       PassengerId HomePlanet CryoSleep    Cabin  Destination          Age  \\\n",
      "count         6954       6786      6777     6796         6815  6806.000000   \n",
      "unique        6954          3         2     5441            3          NaN   \n",
      "top        2513_01      Earth     False  D/176/S  TRAPPIST-1e          NaN   \n",
      "freq             1       3691      4377        7         4733          NaN   \n",
      "mean           NaN        NaN       NaN      NaN          NaN    28.828093   \n",
      "std            NaN        NaN       NaN      NaN          NaN    14.446399   \n",
      "min            NaN        NaN       NaN      NaN          NaN     0.000000   \n",
      "25%            NaN        NaN       NaN      NaN          NaN    19.000000   \n",
      "50%            NaN        NaN       NaN      NaN          NaN    27.000000   \n",
      "75%            NaN        NaN       NaN      NaN          NaN    38.000000   \n",
      "max            NaN        NaN       NaN      NaN          NaN    79.000000   \n",
      "\n",
      "          VIP   RoomService     FoodCourt  ShoppingMall           Spa  \\\n",
      "count    6792   6828.000000   6814.000000   6789.000000   6820.000000   \n",
      "unique      2           NaN           NaN           NaN           NaN   \n",
      "top     False           NaN           NaN           NaN           NaN   \n",
      "freq     6636           NaN           NaN           NaN           NaN   \n",
      "mean      NaN    222.822935    456.714705    175.499043    315.693842   \n",
      "std       NaN    674.900407   1574.797221    613.969158   1118.074541   \n",
      "min       NaN      0.000000      0.000000      0.000000      0.000000   \n",
      "25%       NaN      0.000000      0.000000      0.000000      0.000000   \n",
      "50%       NaN      0.000000      0.000000      0.000000      0.000000   \n",
      "75%       NaN     46.000000     84.750000     30.000000     61.250000   \n",
      "max       NaN  14327.000000  27723.000000  23492.000000  18572.000000   \n",
      "\n",
      "              VRDeck                Name Transported  \n",
      "count    6803.000000                6795        6954  \n",
      "unique           NaN                6785           2  \n",
      "top              NaN  Elaney Webstephrey        True  \n",
      "freq             NaN                   2        3500  \n",
      "mean      304.189769                 NaN         NaN  \n",
      "std      1170.639327                 NaN         NaN  \n",
      "min         0.000000                 NaN         NaN  \n",
      "25%         0.000000                 NaN         NaN  \n",
      "50%         0.000000                 NaN         NaN  \n",
      "75%        49.500000                 NaN         NaN  \n",
      "max     24133.000000                 NaN         NaN  \n"
     ]
    }
   ],
   "source": [
    "# Overview dei dataset\n",
    "print(train_df.dtypes)\n",
    "print(train_df.describe(include = 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per calcolare la dipendenza tra feature categoriche con il chi-square test\n",
    "def chi_square(f1, f2):\n",
    "    # Cross tabulation between GENDER and APPROVE_LOAN\n",
    "    crosstab_result=pd.crosstab(index=f1,columns=f2)\n",
    "    print(crosstab_result)\n",
    "\n",
    "    # Performing Chi-sq test\n",
    "    test = chi2_contingency(crosstab_result)\n",
    "    \n",
    "    # P-Value is the Probability of H0 being True\n",
    "    # If P-Value&gt;0.05 then only we Accept the assumption(H0)\n",
    "    \n",
    "    print('The P-Value of the ChiSq Test is:', test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategia: Home_planet\n",
    "# Si nota che tutti gli appartenenti allo stesso gruppo hanno lo stesso home planet e quindi per i nan di home planet si può\n",
    "# assegnare il valore dell'home planet del gruppo (che sarà uguale alla moda). Restano problematici i gruppi composti da una\n",
    "# sola persona, si introduce quindi una nuova categoria di home planet per persona con origine sconoosciuta.\n",
    "\n",
    "def mv_hp_d(dataset):\n",
    "    solo_hp_nan = train_df[(train_df['HomePlanet'].isna()) & (train_df['Solo']==1)].shape[0]\n",
    "    tot_hp_nan = train_df['HomePlanet'].isna().sum() \n",
    "    diff = tot_hp_nan - solo_hp_nan\n",
    "    print(f\"Numero di persone con HomePlanet nullo: {str(tot_hp_nan)}\")\n",
    "    print(f\"Numero di gruppi con HomePlanet nullo: {str(diff)}\")\n",
    "    print(f\"Numero di persone da sole con HomePlanet nullo: {str(solo_hp_nan)}\")\n",
    "\n",
    "    group_hp = train_df[(train_df['Solo']==0)].groupby('Group')['HomePlanet'].nunique().value_counts()\n",
    "    print(f\"Tutti gli appartenenti allo stesso gruppo hanno stesso home planet? {group_hp.shape[0]==1}\")\n",
    "    chi_square(dataset['Destination'], dataset['Group'])\n",
    "    \n",
    "    # HomePlanet\n",
    "    dataset['HomePlanet'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['HomePlanet'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['HomePlanet'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['HomePlanet'].transform(lambda x: x.fillna(\"unknown\"))\n",
    "    print(f\"Numero di persone con HomePlanet nullo: {str(dataset['HomePlanet'].isna().sum())}\")\n",
    "\n",
    "    # Destination\n",
    "    dataset['Destination'] = dataset['Destination'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    print(f\"Numero di persone con Destination nullo: {str(dataset['Destination'].isna().sum())}\")\n",
    "\n",
    "# Strategia: Age\n",
    "# Si distinguono 3 casi di persone con Age nullo: persone sole, persone con famiglia che non spendono e persone con famiglia che spendono.\n",
    "# Per assegnare l'età si usa la mediana del caso di appartenenza, immaginando che è meno probabile che una persona sola sia un bambino\n",
    "# e che al contrario è più probabile che una persona che non spende, ma è in un gruppo lo sia.\n",
    "def mv_age(dataset):\n",
    "    solo = dataset['Solo']==1\n",
    "    family_no_spending = (dataset['Family_size']>1) & (dataset['No_spending']==1)\n",
    "    family_spending = (dataset['Family_size']>1) & (dataset['No_spending']==0)\n",
    "    \n",
    "    print(f\"Numero di persone con Age nullo: {str(dataset['Age'].isna().sum())}, di cui:\")\n",
    "    print(f\"Persone sole: {str(dataset['Age'][solo].isna().sum())}\")\n",
    "    print(f\"Persone con famiglia che non spendono: {str(dataset['Age'][family_no_spending].isna().sum())}\")   \n",
    "    print(f\"Persone con famiglia che spendono: {str(dataset['Age'][family_spending].isna().sum())}\")\n",
    "\n",
    "    dataset['Age'][solo] = dataset[solo]['Age'].transform(lambda x: x.fillna(dataset[solo]['Age'].median()))\n",
    "    dataset['Age'][family_no_spending] = dataset[family_no_spending]['Age'].transform(lambda x: x.fillna(dataset[family_no_spending]['Age'].median()))\n",
    "    dataset['Age'][family_spending] = dataset[family_spending]['Age'].transform(lambda x: x.fillna(dataset[family_spending]['Age'].median()))\n",
    "\n",
    "    print(f\"Numero di persone con Age nullo: {str(dataset['Age'].isna().sum())}\")   \n",
    "\n",
    "\n",
    "# Strategia: Surname\n",
    "# Si osserva che i gruppi sono per gran parte composti da persone con lo stesso cognome, quindi si può assegnare la moda del cognome del gruppo\n",
    "# alle persone con cognome nullo. Per i gruppi composti da una sola persona si assegna cognome 'unknown'.\n",
    "def mv_surname(dataset):\n",
    "    # Raggruppare il dataset per gruppo e contare il numero di cognomi unici\n",
    "    #TODO: print sbagliata\n",
    "    group_surname = dataset[(dataset['Solo']==0)].groupby('Group')['Surname'].nunique().value_counts()\n",
    "    print(f\"Numero cognomi diversi per gruppo {group_surname}\")\n",
    "\n",
    "    print(f\"Numero di persone con Surname nullo: {str(dataset['Surname'].isna().sum())}\")\n",
    "    dataset['Surname'][(dataset['Solo']==0)] = dataset[(dataset['Solo']==0)].groupby('Group')['Surname'].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "    dataset['Surname'][(dataset['Solo']==1)] = dataset[(dataset['Solo']==1)].groupby('Group')['Surname'].transform(lambda x: x.fillna(\"Unknown\"))\n",
    "    print(f\"Numero di persone con Surname nullo: {str(dataset['Surname'].isna().sum())}\")\n",
    "\n",
    "# Strategia: RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "# Si sostituiscono i valori nulli con la media di spesa delle altre categorie non nulle, dopo aver osservato che ogni persona ha almeno un valore\n",
    "# di spesa non nullo. Ad esempio, se una persona ha spesa nulla per RoomService e ShoppingMall, ma ha spesa per FoodCourt e Spa, si assegna la media\n",
    "# di FoodCourt e Spa per RoomService e ShoppingMall.\n",
    "def mv_exp(dataset):\n",
    "    services = (dataset['RoomService'].isna()) | (dataset['FoodCourt'].isna()) | (dataset['ShoppingMall'].isna()) | (dataset['Spa'].isna()) | (dataset['VRDeck'].isna())\n",
    "    print(f\"Persone con servizi nulli: {str(dataset[services].shape[0])}\")\n",
    "    # Per ogni persona con almeno un servizio nullo, si calcola la media delle spese non nulle\n",
    "    dataset['RoomService'] = dataset['RoomService'].fillna(dataset[['FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['FoodCourt'] = dataset['FoodCourt'].fillna(dataset[['RoomService', 'ShoppingMall', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['ShoppingMall'] = dataset['ShoppingMall'].fillna(dataset[['RoomService', 'FoodCourt', 'Spa', 'VRDeck']].mean(axis=1))\n",
    "    dataset['Spa'] = dataset['Spa'].fillna(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'VRDeck']].mean(axis=1))\n",
    "    dataset['VRDeck'] = dataset['VRDeck'].fillna(dataset[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa']].mean(axis=1))\n",
    "\n",
    "# Controllare se i gruppi hanno tutti lo stesso valore di cabin_side\n",
    "def check_cabin_side(dataset):\n",
    "    # Raggruppa il dataset per 'Group' e conta i valori unici di 'Cabin_side'\n",
    "    group_cabin_side_counts = dataset.groupby('Group')['Cabin_side'].nunique().value_counts()\n",
    "    \n",
    "    # Visualizza il risultato\n",
    "    print(group_cabin_side_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persone con servizi nulli: 691\n",
      "Numero di persone con HomePlanet nullo: 168\n",
      "Numero di gruppi con HomePlanet nullo: 64\n",
      "Numero di persone da sole con HomePlanet nullo: 104\n",
      "Tutti gli appartenenti allo stesso gruppo hanno stesso home planet? True\n",
      "Group          2     3     4     5     6     8     9     10    12    14    \\\n",
      "Destination                                                                 \n",
      "55 Cancri e       0     0     0     0     0     2     0     0     0     1   \n",
      "PSO J318.5-22     0     0     0     1     0     0     0     0     0     0   \n",
      "TRAPPIST-1e       1     2     1     0     2     1     1     1     1     0   \n",
      "\n",
      "Group          ...  9264  9267  9268  9270  9272  9274  9275  9278  9279  9280  \n",
      "Destination    ...                                                              \n",
      "55 Cancri e    ...     1     0     0     1     0     0     0     0     0     0  \n",
      "PSO J318.5-22  ...     0     0     0     0     0     0     0     1     0     0  \n",
      "TRAPPIST-1e    ...     0     2     1     0     1     1     2     0     1     1  \n",
      "\n",
      "[3 rows x 5127 columns]\n",
      "The P-Value of the ChiSq Test is: 0.00016495054761429579\n",
      "Numero di persone con HomePlanet nullo: 0\n",
      "Numero di persone con Destination nullo: 0\n",
      "Numero cognomi diversi per gruppo Surname\n",
      "1    880\n",
      "2    187\n",
      "3     15\n",
      "4      1\n",
      "Name: count, dtype: int64\n",
      "Numero di persone con Surname nullo: 159\n",
      "Numero di persone con Surname nullo: 0\n",
      "Numero di persone con Age nullo: 148, di cui:\n",
      "Persone sole: 87\n",
      "Persone con famiglia che non spendono: 40\n",
      "Persone con famiglia che spendono: 21\n",
      "Numero di persone con Age nullo: 0\n",
      "Cabin_side\n",
      "1    5126\n",
      "0      89\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def preprocess_data(dataset):\n",
    "    # Viene aggiunta una colonna per contare il numero di persone nel gruppo di appartenenza e se la persona è da sola\n",
    "    dataset['Group'] = dataset['PassengerId'].apply(lambda x: x.split('_')[0]).astype(int)\n",
    "    dataset['Group_size']=dataset['Group'].map(lambda x: dataset['Group'].value_counts()[x])\n",
    "    dataset['Solo']=(dataset['Group_size']==1).astype(int)\n",
    "\n",
    "    # Viene creata una colonna per il cognome e si rimuove la colonna Name\n",
    "    dataset['Name'].fillna('Unknown Unknown', inplace=True)\n",
    "    dataset['Surname']=dataset['Name'].str.split().str[-1]\n",
    "    dataset.loc[dataset['Surname']=='Unknown','Surname']=np.nan\n",
    "    dataset.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "    # Vengono riempiti i valori nulli delle colonne RoomService, FoodCourt, ShoppingMall, Spa, VRDeck\n",
    "    mv_exp(dataset)\n",
    "    \n",
    "    # Vengono prese tutte le colonne che rappresentano le spese e si aggiunge una colonna per contare il\n",
    "    # totale speso dalla persona e una colonna booleana per indicare se la persona non ha speso nulla\n",
    "    exp_feats=['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    dataset['Expenditure']=dataset[exp_feats].sum(axis=1)\n",
    "    dataset['No_spending']=(dataset['Expenditure']==0).astype(int)\n",
    "\n",
    "    # Vengono riempiti i valori nulli della colonna HomePlanet, Destination, Surmane\n",
    "    mv_hp_d(dataset)\n",
    "    mv_surname(dataset)\n",
    "\n",
    "    # Viene aggiunta una colonna per contare le persone che hanno lo stesso cognome\n",
    "    dataset['Family_size']=dataset[(dataset['Surname']!='Unknown')].groupby('Group')['Surname'].transform('count')\n",
    "    dataset.loc[dataset['Surname']=='Unknown','Family_size']=1\n",
    "    dataset.loc[dataset['Family_size']>100,'Family_size']=np.nan\n",
    "\n",
    "    # Vengono riempiti i valori nulli della colonna Age\n",
    "    mv_age(dataset)\n",
    "\n",
    "\n",
    "    # Viene aggiunta una colonna che assegna ogni passeggero al gruppo di età di appartenenza\n",
    "    dataset['Age_group']=0\n",
    "    dataset.loc[dataset['Age']<=12,'Age_group']='Age_0-12'\n",
    "    dataset.loc[(dataset['Age']>12) & (dataset['Age']<18),'Age_group']='Age_13-17'\n",
    "    dataset.loc[(dataset['Age']>=18) & (dataset['Age']<=25),'Age_group']='Age_18-25'\n",
    "    dataset.loc[(dataset['Age']>25) & (dataset['Age']<=30),'Age_group']='Age_26-30'\n",
    "    dataset.loc[(dataset['Age']>30) & (dataset['Age']<=50),'Age_group']='Age_31-50'\n",
    "    dataset.loc[dataset['Age']>50,'Age_group']='Age_51+'\n",
    "\n",
    "    # Separazione della colonna 'Cabin' nelle colonne deck, number e side\n",
    "    dataset['Cabin'].fillna('Z/9999/Z', inplace=True)\n",
    "\n",
    "    dataset['Cabin_deck'] = dataset['Cabin'].apply(lambda x: x.split('/')[0])\n",
    "    dataset['Cabin_number'] = dataset['Cabin'].apply(lambda x: x.split('/')[1]).astype(int)\n",
    "    dataset['Cabin_side'] = dataset['Cabin'].apply(lambda x: x.split('/')[2])\n",
    "\n",
    "    dataset.loc[dataset['Cabin_deck']=='Z', 'Cabin_deck']=np.nan\n",
    "    dataset.loc[dataset['Cabin_number']==9999, 'Cabin_number']=np.nan\n",
    "    dataset.loc[dataset['Cabin_side']=='Z', 'Cabin_side']=np.nan\n",
    "\n",
    "    dataset.drop('Cabin', axis=1, inplace=True)\n",
    "    check_cabin_side(dataset)\n",
    "\n",
    "\n",
    "\n",
    "preprocess_data(train_df)\n",
    "#preprocess_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "HomePlanet        0\n",
      "CryoSleep       177\n",
      "Destination       0\n",
      "Age               0\n",
      "VIP             162\n",
      "RoomService       0\n",
      "FoodCourt         0\n",
      "ShoppingMall      0\n",
      "Spa               0\n",
      "VRDeck            0\n",
      "Transported       0\n",
      "Group             0\n",
      "Group_size        0\n",
      "Solo              0\n",
      "Surname           0\n",
      "Expenditure       0\n",
      "No_spending       0\n",
      "Family_size       0\n",
      "Age_group         0\n",
      "Cabin_deck      158\n",
      "Cabin_number    158\n",
      "Cabin_side      158\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# stampare le colonne con i valori nulli\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
