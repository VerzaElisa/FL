{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3759a0bb-6414-4878-aa54-2c914dd66df9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3759a0bb-6414-4878-aa54-2c914dd66df9",
        "outputId": "c3009e83-8052-43bd-bcf3-d7c60855a44c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-02 12:57:35.090463: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-02 12:57:35.090577: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-02 12:57:35.092433: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-02 12:57:35.300477: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/ella/Desktop/Progetto/venv-federated/lib/python3.9/site-packages/tensorflow_federated\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_federated as tff\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEST_SIZE = 0.2\n",
        "NUM_CLIENTS = 5\n",
        "ACTIVE_CLIENTS = 5\n",
        "BATCH_SIZE = 5\n",
        "path = os.path.dirname(tff.__file__)\n",
        "print(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "M9wR1m-xJHCG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9wR1m-xJHCG",
        "outputId": "ce971eb6-5b1c-4b55-b479-415ddb81bcdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPUs disponibili:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "TensorFlow sta usando la GPU\n"
          ]
        }
      ],
      "source": [
        "# Lista delle GPU disponibili\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"GPUs disponibili: \", gpus)\n",
        "\n",
        "# Verifica se TensorFlow utilizza la GPU\n",
        "if gpus:\n",
        "    print(\"TensorFlow sta usando la GPU\")\n",
        "else:\n",
        "    print(\"TensorFlow non sta usando la GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8297d26f-e0bf-480b-9c3f-4c7df497b051",
      "metadata": {
        "id": "8297d26f-e0bf-480b-9c3f-4c7df497b051"
      },
      "outputs": [],
      "source": [
        "# Import del dataset e divisione in train e test\n",
        "df = pd.read_csv('comptagesvelo2015.csv')\n",
        "train_df, test_df = train_test_split(df, test_size = TEST_SIZE, random_state = 42)\n",
        "\n",
        "# Funzione per il preprocessiSng dei dati del singolo client con i pixel disposti in una matrice\n",
        "# 28x28 il dataset viene restitutito diviso in batch\n",
        "def preprocess(dataset):\n",
        "  def batch_format_fn(element):\n",
        "      return (tf.reshape(float(element['pixels']/255), [-1, 28, 28, 1]),\n",
        "              tf.reshape(element['label'], [-1, 1]))\n",
        "  return dataset.batch(BATCH_SIZE).map(batch_format_fn)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3530df22-440e-4ca2-8cf2-d317c2f03ae8",
      "metadata": {
        "id": "3530df22-440e-4ca2-8cf2-d317c2f03ae8"
      },
      "outputs": [],
      "source": [
        "# Funzione per la creazione di un dataset ClientData a partire dal dataset di training a cui viene\n",
        "# aggiunta una colonna client_nums che assegna ad ogni riga un client randomico\n",
        "def create_clients(dataset):\n",
        "    # Viene creata una lista randomica di client\n",
        "    client_nums = list(range(NUM_CLIENTS))\n",
        "    generator = np.random.default_rng(42)\n",
        "    clients = generator.choice(client_nums, len(dataset))\n",
        "    dataset['client_nums'] = clients\n",
        "\n",
        "    # Viene convertito il dataset in dizionari, uno per ogni client, con label e pixel associati\n",
        "    client_train_dataset = collections.OrderedDict()\n",
        "    grouped_dataset = dataset.groupby('client_nums')\n",
        "    for key, item in grouped_dataset:\n",
        "        current_client = grouped_dataset.get_group(key)\n",
        "        data = collections.OrderedDict((('label',current_client.iloc[:,0]), ('pixels', current_client.iloc[:,1:-1])))\n",
        "        client_train_dataset[key] = data\n",
        "\n",
        "    # I dizionari vengono convertiti in ClientDataset\n",
        "    def serializable_dataset_fn(client_id):\n",
        "        client_data = client_train_dataset[client_id]\n",
        "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
        "\n",
        "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
        "        client_ids=list(client_train_dataset.keys()),\n",
        "        serializable_dataset_fn=serializable_dataset_fn\n",
        "    )\n",
        "\n",
        "    return tff_train_data\n",
        "\n",
        "# Funzione per la creazione di un dataset ClientData a partire dal dataset di test\n",
        "# Il test Ã¨ centralizzato, quindi viene impostato un client fittizio a zero\n",
        "def create_test(dataset):\n",
        "    zeros = [0]*len(dataset)\n",
        "    dataset['client_nums'] = zeros\n",
        "\n",
        "    # Viene convertito il dataset in un dizionario\n",
        "    client_train_dataset = collections.OrderedDict()\n",
        "    grouped_dataset = dataset.groupby('client_nums')\n",
        "    current_client = grouped_dataset.get_group(0)\n",
        "    data = collections.OrderedDict((('label',current_client.iloc[:,0]), ('pixels', current_client.iloc[:,1:-1])))\n",
        "    client_train_dataset[0] = data\n",
        "\n",
        "    # Il dizionario viene convertito in ClientDataset\n",
        "    def serializable_dataset_fn(client_id = 0):\n",
        "        client_data = client_train_dataset[0]\n",
        "        return tf.data.Dataset.from_tensor_slices(client_data)\n",
        "\n",
        "    tff_train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(\n",
        "        client_ids=[0],\n",
        "        serializable_dataset_fn=serializable_dataset_fn\n",
        "    )\n",
        "\n",
        "    return tff_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e28200eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0:\n",
            "  Memoria libera: 531.83 MB\n",
            "  Memoria totale: 531.83 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-02 13:03:21.315189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 1743 MB memory:  -> device: 0, name: NVIDIA GeForce MX230, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "\n",
        "def print_gpu_memory():\n",
        "    gpus = get_available_gpus()\n",
        "    for gpu in gpus:\n",
        "        gpu_name = gpu.split(':')[-1]\n",
        "        gpu_mem = tf.config.experimental.get_memory_info(gpu)\n",
        "        print(f\"GPU {gpu_name}:\")\n",
        "        print(f\"  Memoria libera: {gpu_mem['current'] / (1024 ** 2):.2f} MB\")\n",
        "        print(f\"  Memoria totale: {gpu_mem['peak'] / (1024 ** 2):.2f} MB\")\n",
        "\n",
        "print_gpu_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "059eb73f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creazione della lista contenente i client con i relativi dataset\n",
        "client_data_df = create_clients(train_df)\n",
        "client_ids = sorted(client_data_df.client_ids)[:ACTIVE_CLIENTS]\n",
        "federated_train_data = [preprocess(client_data_df.create_tf_dataset_for_client(x)) for x in client_ids]\n",
        "\n",
        "# Creazione del dataset di test\n",
        "central_test_df = create_test(test_df)\n",
        "central_test_df = preprocess(central_test_df.create_tf_dataset_for_client(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bd3779-9d9f-4b49-9a2f-783456deccc5",
      "metadata": {
        "id": "46bd3779-9d9f-4b49-9a2f-783456deccc5"
      },
      "source": [
        "La struttura del train Ã¨ la seguente:\n",
        "    * federated_train_data ha un entry per client\n",
        "    * Ogni client ha un certo numero di batch\n",
        "    * Ogni batch Ã¨ un array con due elementi, uno contiene tutti i pixel, l'altro tutte le label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854923f9-5956-4a3f-a91f-4666f495a27f",
      "metadata": {
        "id": "854923f9-5956-4a3f-a91f-4666f495a27f",
        "outputId": "53b00913-ea51-45d9-e656-3bc92b6de272"
      },
      "outputs": [],
      "source": [
        "# Controlli consistenza datast vs. DataClient\n",
        "\n",
        "print('Numero di clients: '+str(len(client_data_df.client_ids)))\n",
        "total = 0\n",
        "for x in client_data_df.client_ids:\n",
        "    num_elem = 0\n",
        "    for i in federated_train_data[x]:\n",
        "        num = len(list(i[1]))\n",
        "        num_elem += num\n",
        "        total += num\n",
        "    print('Numero di batch per client {}: {}\\nNumero elementi per client: {}'.format(x, str(len(federated_train_data[x])), str(num_elem)))\n",
        "print('TOT TRAIN CD: {} \\nTOT TRAIN DF: {}'.format(total, train_df.shape))\n",
        "\n",
        "\n",
        "num_elem = 0\n",
        "for i in central_test_df:\n",
        "    num = len(list(i[1]))\n",
        "    num_elem += num\n",
        "print('Numero di batch per il test set: {}'.format(str(len(central_test_df))))\n",
        "print('TOT TEST CD: {} \\nTOT TEST DF: {}'.format(str(num_elem), test_df.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f994bd-57f2-47a8-a669-c936cebf5513",
      "metadata": {
        "id": "a0f994bd-57f2-47a8-a669-c936cebf5513"
      },
      "outputs": [],
      "source": [
        "# Creazione del modello con le API di Keras\n",
        "def create_keras_model():\n",
        "  return keras.models.Sequential([keras.layers.Conv2D(filters=32, kernel_size=(5,5), activation='tanh', input_shape=(28, 28, 1), kernel_initializer=\"glorot_normal\"),\n",
        "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
        "                                  keras.layers.Conv2D(filters=48, kernel_size=(5,5), activation='tanh'),\n",
        "                                  keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
        "                                  keras.layers.Conv2D(filters=64, kernel_size=(5,5), padding='same', activation='tanh'),\n",
        "                                  keras.layers.Flatten(),\n",
        "                                  keras.layers.Dense(120, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "                                  keras.layers.Dense(84, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
        "                                  keras.layers.Dense(27, activation='softmax')\n",
        "                                ])\n",
        "keras_model = create_keras_model()\n",
        "# Creazione del modello TFF a partire dal modello Keras\n",
        "tff_model = tff.learning.models.functional_model_from_keras(keras_model,\n",
        "                                                            loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                                                            input_spec=federated_train_data[0].element_spec,\n",
        "                                                            metrics_constructor=collections.OrderedDict(accuracy=tf.keras.metrics.SparseCategoricalAccuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d25b236-0bca-4fe4-b6bf-fd2137432162",
      "metadata": {
        "id": "3d25b236-0bca-4fe4-b6bf-fd2137432162"
      },
      "outputs": [],
      "source": [
        "#Al client update si puÃ² aggiungere un parametro che indica il numero di epoche in cui ripetere l'addestramento prima di inviare i pesi al server\n",
        "@tf.function\n",
        "def client_update(model, dataset, initial_weights, client_optimizer):\n",
        "\n",
        "  client_weights = initial_weights.trainable\n",
        "  optimizer_state = client_optimizer.initialize(tf.nest.map_structure(tf.TensorSpec.from_tensor, client_weights))\n",
        "  for _ in range(10):\n",
        "    for batch in dataset:\n",
        "      x, y = batch\n",
        "      with tf.GradientTape() as tape:\n",
        "        tape.watch(client_weights)\n",
        "        # Compute a forward pass on the batch of data\n",
        "        outputs = model.predict_on_batch(model_weights=(client_weights, ()), x=x, training=True)\n",
        "        loss = model.loss(output=outputs, label=y)\n",
        "\n",
        "      # Compute the corresponding gradient\n",
        "      grads = tape.gradient(loss, client_weights)\n",
        "\n",
        "      # Apply the gradient using a client optimizer.\n",
        "      optimizer_state, client_weights = client_optimizer.next(optimizer_state, weights=client_weights, gradients=grads)\n",
        "\n",
        "  return tff.learning.models.ModelWeights(client_weights, non_trainable=())\n",
        "\n",
        "@tf.function\n",
        "def server_update(model, mean_client_weights):\n",
        "  del model\n",
        "  return mean_client_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb91832b-610d-4e4e-a9f3-98c66ddca9d5",
      "metadata": {
        "id": "bb91832b-610d-4e4e-a9f3-98c66ddca9d5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# La logica computazionale di tensorflow federated dev'essere separata rispetto alla logica\n",
        "# computazionale di tensorflow, qui vengono definite le funzioni di inizializzazione del server\n",
        "# e di aggiornamento dei client e del server\n",
        "\n",
        "# Inizializzazione del server con i pesi iniziali del modello\n",
        "@tff.tensorflow.computation\n",
        "def server_init():\n",
        "  return tff.learning.models.ModelWeights(*tff_model.initial_weights)\n",
        "\n",
        "# Vengono salvati i tipi di dato dei pesi del modello e del dataset\n",
        "model_weights_type = server_init.type_signature.result\n",
        "tf_dataset_type = tff.SequenceType(tff.types.tensorflow_to_type(tff_model.input_spec))\n",
        "\n",
        "# Funzione di aggiornamento del client, viene passato il dataset del client edi pesi\n",
        "# aggiornati dal server, restituisce i pesi aggiornati del client\n",
        "@tff.tensorflow.computation(tf_dataset_type, model_weights_type)\n",
        "def client_update_fn(tf_dataset, server_weights):\n",
        "  client_optimizer = tff.learning.optimizers.build_adam(learning_rate=0.01)\n",
        "  return client_update(tff_model, tf_dataset, server_weights, client_optimizer)\n",
        "\n",
        "# Funzione di aggiornamento del server, riceve i pesi mediati dai client e restituisce\n",
        "# i pesi aggiornati del server\n",
        "@tff.tensorflow.computation(model_weights_type)\n",
        "def server_update_fn(mean_client_weights):\n",
        "  return server_update(tff_model, mean_client_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc49222d-2f06-44ad-bcde-7b45679d2581",
      "metadata": {
        "id": "dc49222d-2f06-44ad-bcde-7b45679d2581"
      },
      "outputs": [],
      "source": [
        "# Aggiornati i tipi di dato dei pesi del modello e del dataset con i tipi federati\n",
        "# includendo oltre al tipo di dato il placement\n",
        "federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)\n",
        "federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)\n",
        "\n",
        "# Definizione della computazione federata per l'inizializzazione del server\n",
        "# la funzione ritorna i pesi iniziali del modello\n",
        "@tff.federated_computation\n",
        "def initialize_fn():\n",
        "  return tff.federated_eval(server_init, tff.SERVER)\n",
        "\n",
        "# Definizione della computazione federata per un round di training. Si divide in 3 parti:\n",
        "# 1. Broadcast dei pesi del server ai client\n",
        "# 2. Chiamata della funzione di aggiornamento del client\n",
        "# 3. Il server aggiorna i pesi facendo la media dei pesi dei client\n",
        "@tff.federated_computation(federated_server_type, federated_dataset_type)\n",
        "def next_fn(server_weights, federated_dataset):\n",
        "  server_weights_at_client = tff.federated_broadcast(server_weights)\n",
        "  client_weights = tff.federated_map(client_update_fn, (federated_dataset, server_weights_at_client))\n",
        "  server_weights = tff.federated_map(server_update_fn, tff.federated_mean(client_weights))\n",
        "\n",
        "  return server_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45946e2-dfab-40e5-b03c-5222ff0721c1",
      "metadata": {
        "id": "d45946e2-dfab-40e5-b03c-5222ff0721c1",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "def evaluate(model_weights):\n",
        "  keras_model = create_keras_model()\n",
        "  keras_model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "  )\n",
        "  model_weights.assign_weights_to(keras_model)\n",
        "  keras_model.evaluate(central_test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2953253e-27d4-45de-8f4d-14516409eef3",
      "metadata": {
        "id": "2953253e-27d4-45de-8f4d-14516409eef3",
        "outputId": "dc37adcc-b60d-479a-fd5c-6625aeab152e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Viene creato l'iterative process con le funzioni init e next custom\n",
        "federated_algorithm = tff.templates.IterativeProcess(initialize_fn=initialize_fn, next_fn=next_fn)\n",
        "\n",
        "# Inizializzazione del server\n",
        "server_state = federated_algorithm.initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71ccb84-66c6-4553-9336-85d8001768e5",
      "metadata": {
        "id": "b71ccb84-66c6-4553-9336-85d8001768e5",
        "outputId": "f85b4ef1-87cf-4435-a669-4518db38b790"
      },
      "outputs": [],
      "source": [
        "i = 1\n",
        "for _ in range(5):\n",
        "    print('pre server state '+str(i))\n",
        "    server_state = federated_algorithm.next(server_state, federated_train_data)\n",
        "    print('post server state '+str(i))\n",
        "    i+=1\n",
        "evaluate(server_state)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
