{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.metrics import R2Score, CosineSimilarity\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "df = pd.read_csv('datasets/BMIDataSet.csv')\n",
    "\n",
    "df['NObeyesdad'] = ((df['Weight']) / (df['Height']**2))\n",
    "df.rename(columns={'NObeyesdad': 'label'}, inplace=True)\n",
    "\n",
    "print(df.dtypes)\n",
    "# Viene diviso il train set in train e validation set\n",
    "train, test_df = train_test_split(df, test_size = TEST_SIZE, random_state = 42)\n",
    "train_df, val_df = train_test_split(train, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "train_x = train_df.drop(columns=['label'])\n",
    "train_y = train_df['label'].astype('float64')\n",
    "\n",
    "val_x = val_df.drop(columns=['label'])\n",
    "val_y = val_df['label'].astype('float64')\n",
    "\n",
    "test_x = test_df.drop(columns=['label'])\n",
    "test_y = test_df['label'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(dataset):\n",
    "    cat_cols = dataset.select_dtypes(include='object').columns\n",
    "    num_cols = dataset.select_dtypes(exclude='object').columns\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    dataset[num_cols] = scaler.fit_transform(dataset[num_cols])\n",
    "\n",
    "    encoder = OrdinalEncoder()\n",
    "    dataset[cat_cols] = encoder.fit_transform(dataset[cat_cols])\n",
    "    return dataset, scaler, encoder\n",
    "\n",
    "def fs(dataset, dataset_y):\n",
    "    str_path = 'objects/features_BMI.npy'\n",
    "\n",
    "    if not os.path.exists(str_path):\n",
    "        dataset['label'] = dataset_y\n",
    "        correlation_matrix=dataset.corr()\n",
    "        features = correlation_matrix['label'][(correlation_matrix['label']>=0.1) | (correlation_matrix['label']<=-0.1)].index\n",
    "        features = features.drop('label')\n",
    "        print(correlation_matrix['label'].sort_values(ascending=False))\n",
    "        print(features)\n",
    "        np.save(str_path, features)\n",
    "    features = np.load(str_path, allow_pickle=True)\n",
    "    return train_x[features]\n",
    "\n",
    "def one_hot_encoding(dataset):\n",
    "    for column in dataset.columns:\n",
    "        if len(dataset[column].unique()) <= 2:\n",
    "            dataset = pd.get_dummies(dataset, columns=[column])\n",
    "    return dataset.astype('float64')\n",
    "\n",
    "train_x, scaler, encoder = encoding(train_x)\n",
    "train_x = fs(train_x, train_y)\n",
    "train_x = one_hot_encoding(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_test_val(dataset, scaler, encoder):\n",
    "    cat_cols = dataset.select_dtypes(include='object').columns\n",
    "    num_cols = dataset.select_dtypes(exclude='object').columns\n",
    "    dataset[num_cols] = scaler.transform(dataset[num_cols])\n",
    "    dataset[cat_cols] = encoder.transform(dataset[cat_cols])\n",
    "    features = np.load('objects/features_BMI.npy', allow_pickle=True)\n",
    "    dataset = dataset[features]\n",
    "    dataset = dataset.astype(float)\n",
    "    dataset = one_hot_encoding(dataset)\n",
    "    return dataset\n",
    "\n",
    "val_x = preproc_test_val(val_x, scaler, encoder)\n",
    "test_x = preproc_test_val(test_x, scaler, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 256\n",
    "DROPOUT = 0.1\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "loss_str = 'mean_squared_error'\n",
    "\n",
    "def model_fn():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128, kernel_initializer='normal',input_dim = train_x.shape[1], activation='relu'))\n",
    "    model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(64, kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    initial_learning_rate = 0.01\n",
    "    final_learning_rate = 0.0001\n",
    "    learning_rate_decay_factor = (final_learning_rate / initial_learning_rate)**(1/200)\n",
    "    steps_per_epoch = int(train_x.shape[0]/BATCH_SIZE)\n",
    "\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate,\n",
    "        decay_steps=steps_per_epoch,\n",
    "        decay_rate=learning_rate_decay_factor,\n",
    "        staircase=True)\n",
    "    model.compile(optimizer = keras.optimizers.Adam(learning_rate=lr_schedule), loss = loss_str, metrics = [loss_str, 'mae', CosineSimilarity(axis=1), R2Score()])\n",
    "    return model\n",
    "\n",
    "model = model_fn()\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=[early_stopping_cb],\n",
    "                    validation_data=(val_x, val_y))\n",
    "\n",
    "EPOCHS = len(history.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].plot(history.history['val_mean_squared_error'])\n",
    "axs[0, 0].plot(history.history['mean_squared_error'])\n",
    "axs[0, 0].legend(['val_mse', 'mse'])\n",
    "\n",
    "axs[0, 1].plot(history.history['val_mae'])\n",
    "axs[0, 1].plot(history.history['mae'])\n",
    "axs[0, 1].legend(['val_mae', 'mae'])\n",
    "\n",
    "axs[1, 0].plot(history.history['val_cosine_similarity'])\n",
    "axs[1, 0].plot(history.history['cosine_similarity'])\n",
    "axs[1, 0].legend(['val_cosine_similarity', 'cosine_similarity'])\n",
    "\n",
    "axs[1, 1].plot(history.history['val_r2_score'])\n",
    "axs[1, 1].plot(history.history['r2_score'])\n",
    "axs[1, 1].legend(['val_r2_score', 'r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y)\n",
    "print(score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(columns=['label'])\n",
    "train_y = train['label'].astype(float)\n",
    "\n",
    "test_x = test_df.drop(columns=['label'])\n",
    "test_y = test_df['label'].astype(float)\n",
    "train_x = preproc_test_val(train_x, scaler, encoder)\n",
    "test_x = preproc_test_val(test_x, scaler, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_fn()\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20, min_delta=0.0001, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=[early_stopping_cb],\n",
    "                    validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].plot(history.history['val_mean_squared_error'])\n",
    "axs[0, 0].plot(history.history['mean_squared_error'])\n",
    "axs[0, 0].legend(['val_mse', 'mse'])\n",
    "\n",
    "axs[0, 1].plot(history.history['val_mae'])\n",
    "axs[0, 1].plot(history.history['mae'])\n",
    "axs[0, 1].legend(['val_mae', 'mae'])\n",
    "\n",
    "axs[1, 0].plot(history.history['val_cosine_similarity'])\n",
    "axs[1, 0].plot(history.history['cosine_similarity'])\n",
    "axs[1, 0].legend(['val_cosine_similarity', 'cosine_similarity'])\n",
    "\n",
    "axs[1, 1].plot(history.history['val_r2_score'])\n",
    "axs[1, 1].plot(history.history['r2_score'])\n",
    "axs[1, 1].legend(['val_r2_score', 'r2_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_x, train_y], axis=1)\n",
    "train_df.to_csv('datasets/train_BMI.csv', index=False)\n",
    "test_df = pd.concat([test_x, test_y], axis=1)\n",
    "test_df.to_csv('datasets/test_BMI.csv', index=False)\n",
    "\n",
    "model.save('models/titanic_model')\n",
    "model.save_weights('models/titanic_weights')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-federated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
