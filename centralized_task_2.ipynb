{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OrdinalEncoder\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense\n",
    "from keras.initializers import GlorotUniform\n",
    "from keras.initializers import HeUniform\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adamax, Nadam, Ftrl\n",
    "\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials, space_eval, STATUS_OK\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)\n",
    "\n",
    "TEST_SIZE = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import del dataset e divisione in train e test\n",
    "df = pd.read_csv('datasets/ObesityDataSet.csv')\n",
    "# Sostituire la colonna 'NObeyesdad' con il risultato della seguente formula: Weight/(Height^2)\n",
    "df['NObeyesdad'] = ((df['Weight']) / (df['Height']**2))\n",
    "df.rename(columns={'NObeyesdad': 'label'}, inplace=True)\n",
    "\n",
    "# Viene diviso il train set in train e validation set\n",
    "train_df, test_df = train_test_split(df, test_size = TEST_SIZE, random_state = 42)\n",
    "train_df, val_df = train_test_split(train_df, test_size = TEST_SIZE, random_state = 42)\n",
    "\n",
    "train_x = train_df.drop(columns=['label'])\n",
    "train_y = train_df['label'].astype('float64')\n",
    "\n",
    "val_x = val_df.drop(columns=['label'])\n",
    "val_y = val_df['label'].astype('float64')\n",
    "\n",
    "test_x = test_df.drop(columns=['label'])\n",
    "test_y = test_df['label'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                                   float64\n",
      "Height                                float64\n",
      "Weight                                float64\n",
      "FCVC                                  float64\n",
      "CAEC                                  float64\n",
      "CH2O                                  float64\n",
      "FAF                                   float64\n",
      "CALC                                  float64\n",
      "family_history_with_overweight_0.0    float64\n",
      "family_history_with_overweight_1.0    float64\n",
      "FAVC_0.0                              float64\n",
      "FAVC_1.0                              float64\n",
      "SCC_0.0                               float64\n",
      "SCC_1.0                               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "cat_cols = train_x.select_dtypes(include='object').columns\n",
    "num_cols = train_x.select_dtypes(exclude='object').columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x[num_cols] = scaler.fit_transform(train_x[num_cols])\n",
    "\n",
    "# Applica l'encoding ai dati categoriali nella lista ord_list\n",
    "encoder = OrdinalEncoder()\n",
    "train_x[cat_cols] = encoder.fit_transform(train_x[cat_cols])\n",
    "\n",
    "def fs(dataset, dataset_y):\n",
    "    str_path = 'objects/features_obesity.npy'\n",
    "    #controllare se esiste il file features.npy\n",
    "    if not os.path.exists(str_path):\n",
    "        dataset['label'] = dataset_y\n",
    "        correlation_matrix=dataset.corr()\n",
    "        features = correlation_matrix['label'][(correlation_matrix['label']>=0.1) | (correlation_matrix['label']<=-0.1)].index\n",
    "        features = features.drop('label')\n",
    "        print(correlation_matrix['label'].sort_values(ascending=False))\n",
    "        print(features)\n",
    "        np.save(str_path, features)\n",
    "    features = np.load(str_path, allow_pickle=True)\n",
    "    return train_x[features]\n",
    "\n",
    "#se la colonna ha solo due valori diversi fare one hot encoding\n",
    "def one_hot_encoding(dataset):\n",
    "    for column in dataset.columns:\n",
    "        if len(dataset[column].unique()) <= 2:\n",
    "            dataset = pd.get_dummies(dataset, columns=[column])\n",
    "    return dataset.astype('float64')\n",
    "\n",
    "train_x = fs(train_x, train_y)\n",
    "train_x = one_hot_encoding(train_x)\n",
    "print(train_x.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-federated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
