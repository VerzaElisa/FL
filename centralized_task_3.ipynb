{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from shapely.geometry import  Point\n",
    "#import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OrdinalEncoder\n",
    "#import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import urllib.request\n",
    "import shutil\n",
    "import zipfile\n",
    "import os\n",
    "import re\n",
    "#import contextily as ctx\n",
    "#import geoplot as gplt\n",
    "#import lightgbm as lgb\n",
    "#import eli5\n",
    "#from eli5.sklearn import PermutationImportance\n",
    "#from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "#from pdpbox import pdp, get_dataset, info_plots\n",
    "#import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('datasets/SanFranciscoCriminality.csv', parse_dates=['Dates'])\n",
    "ds.drop(columns=['Descript'], inplace=True)\n",
    "encoder = OrdinalEncoder()\n",
    "ds['Category'] = encoder.fit_transform(ds[['Category']])\n",
    "\n",
    "train_df, test_df = train_test_split(ds, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_x = train_df.drop(columns=['Category'])\n",
    "train_y = train_df['Category']\n",
    "\n",
    "val_x = val_df.drop(columns=['Category'])\n",
    "val_y = val_df['Category']\n",
    "\n",
    "test_x = test_df.drop(columns=['Category'])\n",
    "test_y = test_df['Category']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "resolution = []\n",
    "resolution.append(train_x['Resolution'].str.split(',').apply(len))\n",
    "print(np.unique(np.array(resolution)))\n",
    "\n",
    "def second_resolution(elem):\n",
    "    return elem.split(',')[1] if len(elem.split(',')) > 1 else 'NONE'\n",
    "\n",
    "def resolution(dataset):\n",
    "    print(dataset.columns)\n",
    "    dataset['Resolution_1'] = dataset['Resolution'].str.split(',').str[0]\n",
    "    dataset['Resolution_2'] = dataset['Resolution'].map(second_resolution)\n",
    "    return dataset.drop(columns=['Resolution'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_x.loc[~train_x['Y'].astype(str).str.startswith('37'), 'Y'] = np.nan\n",
    "train_x.loc[~train_x['X'].astype(str).str.startswith('-122'), 'X'] = np.nan\n",
    "\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "\n",
    "for district in train_x['PdDistrict'].unique():\n",
    "    train_x.loc[train_x['PdDistrict'] == district, ['X', 'Y']] = imp.fit_transform(train_x.loc[train_x['PdDistrict'] == district, ['X', 'Y']])\n",
    "print(train_x['Y'].isnull().sum())\n",
    "print(train_x['X'].isnull().sum())\n",
    "def feature_engineering(data):\n",
    "    data = resolution(data)\n",
    "    data['Date'] = pd.to_datetime(data['Dates'].dt.date)\n",
    "    data['n_days'] = (data['Date'] - data['Date'].min()).apply(lambda x: x.days)\n",
    "    data['Day'] = data['Dates'].dt.day\n",
    "    data['DayOfWeek'] = data['Dates'].dt.weekday\n",
    "    data['Month'] = data['Dates'].dt.month\n",
    "    data['Year'] = data['Dates'].dt.year\n",
    "    data['Hour'] = data['Dates'].dt.hour\n",
    "    data['Minute'] = data['Dates'].dt.minute\n",
    "    data['Block'] = data['Address'].str.contains('block', case=False)\n",
    "    \n",
    "    data.drop(columns=['Dates','Date','Address'], inplace=True)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def fs(dataset, dataset_y):\n",
    "    str_path = 'objects/SFCriminality.npy'\n",
    "    if not os.path.exists(str_path):\n",
    "        dataset['label'] = dataset_y\n",
    "        correlation_matrix=dataset.corr()\n",
    "        features = correlation_matrix['label'][(correlation_matrix['label']>=0.01) | (correlation_matrix['label']<=-0.01)].index\n",
    "        features = features.drop('label')\n",
    "        print(correlation_matrix['label'].sort_values(ascending=False))\n",
    "        print(features)\n",
    "        np.save(str_path, features)\n",
    "    features = np.load(str_path, allow_pickle=True)\n",
    "    return dataset[features]\n",
    "\n",
    "def encoding(dataset, ohe):\n",
    "    # Chiamata al preprocessing\n",
    "    dataset = feature_engineering(dataset)\n",
    "   \n",
    "    num_cols = dataset.select_dtypes(exclude=['object', 'bool']).columns\n",
    "    cat_cols = dataset.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "    # Applica lo scaling ai dati numerici\n",
    "    scaler = StandardScaler()\n",
    "    dataset[num_cols] = scaler.fit_transform(dataset[num_cols])\n",
    "\n",
    "    # Applica l'encoding ai dati categoriali nella lista ord_list\n",
    "    encoder = OrdinalEncoder()\n",
    "    dataset[cat_cols] = encoder.fit_transform(dataset[cat_cols])\n",
    "    dataset = fs(dataset, train_y)\n",
    "\n",
    "    if ohe[0] in dataset.columns:\n",
    "        dataset = pd.get_dummies(dataset, columns=ohe)\n",
    "\n",
    "    return dataset.astype(float), scaler, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Dates', 'DayOfWeek', 'PdDistrict', 'Resolution', 'Address', 'X', 'Y'], dtype='object')\n",
      "PdDistrict      float64\n",
      "X               float64\n",
      "Y               float64\n",
      "Resolution_1    float64\n",
      "Resolution_2    float64\n",
      "n_days          float64\n",
      "Year            float64\n",
      "Hour            float64\n",
      "Minute          float64\n",
      "Block_0.0       float64\n",
      "Block_1.0       float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_x, scaler, encoder = encoding(train_x, ['Block'])\n",
    "print(train_x.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-federated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
